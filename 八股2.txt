1、多级缓存架构？








    客户端缓存（静态资源）：
            在浏览器层面主要缓存css，js，字体等静态资       源文件
            例如：百度的图标，服务器在响应头中设置expires，浏览器在该段时间将图片以文件缓存在本地，客户端再次访问会看到
                from disk cache的提示，浏览器不再请求服务器，而是直接在本地取图片。
            可以很大程度上缓解浏览器重复请求静态资源的带宽损耗，客户端只需要缓存文件就可以。
    应用层缓存（静态资源）：
            CDN内容分发网络，是互联网静态资源分发的主要技术手段，是广域的互联网应用的基础设施，有效解决了带宽集中占用、资源分发的问题。
            CDN的核心技术是智能DNS。






            例如：大量上海用户访问北京资源。
            但是投入较高，可以租用阿里云、腾讯云、华为云提供的CDN服务，进行租用。

            对于企业级应用，工作人员往往分布在指定的工作区域，或相对固定的场所，再加上并发度并不是很高，
                也就没必要去部署CDN这样重量级的解决方案，可以在架构部署Nginx，利用其自带的静态资源缓存的能力和压缩的功能，
                就可以胜任绝大多数企业级应用场景。Nigix实际是在本地通过一个个目录的方式组织。

    服务层缓存（缓存后端接口查出的数据）：
            进程内缓存：应用中开辟内存空间，进程在运行中载入这块内存，通过本地内存的低延迟，高吞吐特性来提高程序的访问速度（ehCache）
            进程外缓存：分布式缓存（redis），集中缓存。

            先进到远、由快到慢的访问缓存。网络是不确定的，同时访问也是有上限的，所以不能上来就找Redis。
            要在应用端要设计多级应用缓存，通过进程内缓存和进程外缓存结合分摊压力。先看进程内缓存，再看进程外缓存，都查不到再去db，然后写回缓存。

            因为引入多级缓存，要考虑分布式缓存数据一致性问题，此时可以通过MQ主动推送给别的服务实例变更的数据。各实例收到后先删除本地缓存，再重新创建，以保存各实例的数据一致。

2、何时采用多级缓存架构？






3、MySqL集群模式与应用场景
    单库模式：






    读写分离模式：






    分库分表（分片）模式：








        分片算法：




    互联网主流MYsql集群架构：







4、为什么要垂直分表？何时进行垂直分表？
    innodb在1.0以后引入了压缩页，在跨页上解压缩和压缩的执行效率不高，所以表在设计的时候，要尽可能保证每一页内尽可能的多存储一些行数据。
    通过将重要字段剥离，让一页能容纳更多的行，进而缩小数据扫描的页范围，减少跨页检索，检索效率变高。

    数据总量很大且字段超过20，且包含了超长的varchar，CLOB，BLOB。

    主表中主要存放：查询（skuid，商户id）、排序时需要的字段（品牌编号）、高频访问的小字段（商品名称、价格）。
    从表中需要存放：低频访问字段、大字段（图文详情、图片BLOB）

5、为什么在大表严禁使用自增主键？
    在分布式下有严重的问题。
    1、每个分片能承载多少数据，只能靠猜，可能会产生比较大的浪费，不能在运行期间动态扩展的
    2、因为自增主键是在数据库层面生成自增的序列，那么数据库集群必须按主键范围分片（不能hash分片）
    3、范围分片会导致“尾部热点”效应。所有的操作都在一个热点分片上集中处理，该分片的数据库压力会非常大，而其他分片的数据库却没什么压力。

6、为什么不能使用uuid作为主键？
    1、128位，比起整形、长整形浪费空间。
    2、因为无序，作为主键会产生大量的索引重排（可见part1 -51）

7、简介雪花算法SnowFlake？
    有序，且每个机器上序列唯一。






    但是雪花算法要注意时间回拨的问题。但是平常基本不会去时间回拨。
8、布隆过滤器原理？
    二进制数组+n个hash函数。
    在数组中通过hash函数将有效数据所映射的n个位置为1。

    检验数据时，如果全部为1，则代表可能含有该数据。如果出现0，则代表肯定不含此数据。使用的时候只需maven引入redission，其中集成了bloomFilter。

    问题：商品删除了该怎么办？
        布隆过滤器因为某一位二进制可能被多个编号hash映射，因此布隆过滤器无法直接处理删除数据的情况。
        方案1、定时异步重建布隆过滤器（例如每4小时）
        方案2、计数bloomFilter

9、阿里开发规范解读：为啥禁用外键约束？
    表的外键是另一表的主键
    1、额外的数据一致性校验查询，会去另一张表查是否唯一等。
    2、并发问题：外键约束会在主表启用行级锁（共享锁），主表写入或者更新时（开启独占锁），若独占锁一直不释放，详情表会一直阻塞状态。从外界来看，
        所有详情表的写操作，都会因为主表的锁定进入阻塞，可能会导致大量的线程积压，甚至造成系统延迟，崩溃。
    3、级联删除：多层级联删除会让数据变的不可控。禁用是为了数据健壮和可追溯。
    4、数据耦合：数据库层面数据关系产生耦合，数据迁移维护困难，例如：数据多了，将数据源迁移，迁移至大数据库HBASE上，主外键无意义，需要去掉，那么以前程序里未校验的代码可能就出现问题。

10、为什么开发要禁用数据库IP直连？
    会造成两个模块之间强耦合。更换IP时费劲。
    解决：
        1、引入内部DNS：





        2、注册中心：





11、JDBC连接数据库的步骤？
    JDBC连接数据库可以概括为6步，分别是加载JDBC驱动、建立数据库连接、创建一个语句对象、执行一个查询、处理结果集和关闭数据库连接。
    1、加载JDBC驱动
        使用java反射机制中的方法forName()进行加载，如：Class.forName(“com.mysql.jdbc.Driver”);
    2、建立数据库连接
        驱动管理类DriverManager使用特定的驱动程序，通过getConnection(String url)方法建与某个特定数据库的连接。每个JDBC驱动都对应一个URL地址用于自我标识
    3、创建一个语句对象
        创建一个语句对象则需要调用接口java.sql.Connection中的createStatement()方法创建Statement类的语句对象，
        通过创建一个语句对象则可以发送SQL语句到数据库准备执行相应的操作。
    4、执行SQL语句
        将SQL语句发送到数据库之后，根据发送的SQL语句确定执行executeQuery()方法或executeUpdate()方法。
    5、处理结果集
        如果需要从返回的结果集中获取数据，那么可以通过结果集对象调用ResultSet接口的getXXX()方法进行获取。
    6. 关闭数据库连接
        结果集处理完成之后，为了释放资源需要在finally语句块中首先关闭语句对象，再关闭数据库连接，如：
        stmt.close();      //关闭语句对象。
        conn.close();     //关闭数据库连接。

12、浮点数运算
    用BigDecimal
    public class Test {
    public static void main(String[] args) {
        System.out.println((new BigDecimal("2.0")).subtract(new BigDecimal("1.9")).doubleValue());
        }
    }

    api：
        1、BigDecimal(T)
        2、add(BigDecimal) BigDecimal对象中的值相加，返回BigDecimal对象
        3、subtract(BigDecimal) BigDecimal对象中的值相减，返回BigDecimal对象
        4、multiply(BigDecimal) BigDecimal对象中的值相乘，返回BigDecimal对象
        5、divide(BigDecimal) BigDecimal对象中的值相除，返回BigDecimal对象
        6、doubleValue() 将BigDecimal对象中的值转换成双精度数
        7、intValue() 将BigDecimal对象中的值转换成整数
        8、int a = bigdemical.compareTo(bigdemical2) java中对BigDecimal比较大小一般用的是bigdemical的compareTo方法


13、如何实现MySQL异构数据同步？
    阿里Canal + MQ。主要作用：数据监听 + 解耦。
    canal原理：










    整体方案：










14、工厂模式?
    目的：实现调用者和创建者的解耦，调用者无需了解创建细节（比如相关参数），只需使用

    核心本质:
        实例化对象不适用new, 用工厂方法代替
        将选择实现类，创建对象统一管理和控制，从而将调用者跟我们的实现类解耦

    三种模式:
        简单工厂模式:
            用来生产同一等级结构中的任何产品(对于增加新的产品，需要扩展已有代码)
        工厂方法模式:
            用来生产同一等级结构中的固定产品(支持增加任意产品)
        抽象工厂模式:
            围绕一个超级工厂创建其他工厂，该超级工厂又被称为其他工厂的工厂

15、建造者模式？
    使用多个简单的对象一步一步构建成一个复杂的对象，将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示
    指挥者通过指挥不同的工人、按不同的顺序建造，可以得到不同的产品。相比工厂模式的生产零件，建造者模式更像汽车的组装工厂。
    允许用户只通过指定复杂对象的类型和内容就可以构建它们，不需要知道内部的具体构建细节
    何时使用：一些基本部件不会变，而其组合经常变化的时候。

    核心组成：
        1Builder：抽象建造者，定义多个通用方法和构建方法
        2ConcreteBuilder：具体建造者，可以有多个
        3Director：指挥者，控制整个组合过程，将需求交给建造者，由建造者去创建对象
        4Product：产品角色

16、桥接模式？
    桥接模式提高了系统的可扩展性，在不同的维度中任意扩展一个维度，都不需要修改原系统，负责开闭原则。
    就像一座桥，把两个有独立变化的维度组合起来。
    例子：JDBC的驱动程序、JAVA虚拟机实现了平台的无关性。









17、单一索引和联合索引优先使用哪个？
    当创建**(a,b,c)联合索引时，相当于创建了(a)单列索引**，(a,b)联合索引以及**(a,b,c)联合索引**
    复合索引的结构与电话簿类似，人名由姓和名构成，电话簿首先按姓氏对进行排序，然后按名字对有相同姓氏的人进行排序。
        如果您知道姓，电话簿将非常有用；如果您知道姓和名，电话簿则更为有用，但如果您只知道名不姓，电话簿将没有用处。
    所以说创建复合索引时，应该仔细考虑列的顺序。对索引中的所有列执行搜索或仅对前几列执行搜索时，复合索引非常有用；
        仅对后面的任意列执行搜索时，复合索引则没有用处。

    多个单列索引在多条件查询时优化器会选择最优索引策略，可能只用一个索引，也可能将多个索引全用上！
        但多个单列索引底层会建立多个B+索引树，比较占用空间，也会浪费一定插入修改效率，故如果只有多条件联合查询时最好建联合索引！

18、什么是跨域问题？Springboot中关于跨域问题的解决方法？
    URL由协议、域名、端口和路径组成，如果两个URL的协议、域名和端口全部相同，则表示他们同源。
        否则，只要协议、域名、端口有任何一个不同，就是跨域。

    在Spring Boot 2.X应用程序中可以使用注解@CrossOrigin，也可以通过使用WebMvcConfigurer对象来定义全局CORS配置。
        1、可以通过实现WebMvcConfigurer接口，然后重写addCorsMappings方法解决跨域问题。
        2、在Controller或者其中业务方法上加上注解@CrossOrigin(origins = "http://localhost:8080");

19、各种MQ优缺点？














20、Redis的使用场景？
    1、热点数据的缓存
    由于redis访问速度块、支持的数据类型比较丰富，所以redis很适合用来存储热点数据，另外结合expire，
        我们可以设置过期时间然后再进行缓存更新操作，这个功能最为常见，我们几乎所有的项目都有所运用。

    2、限时业务的运用
    redis中可以使用expire命令设置一个键的生存时间，到时间后redis会删除它。利用这一特性可以运用在限时的优惠活动信息、手机验证码等业务场景。

    3、计数器相关问题
      redis由于incrby命令可以实现原子性的递增，所以可以运用于高并发的秒杀活动、分布式序列号的生成、
      具体业务还体现在比如限制一个手机号发多少条短信、一个接口一分钟限制多少请求、一个接口一天限制调用多少次等等。

    4、排行榜相关问题
    关系型数据库在排行榜方面查询速度普遍偏慢，所以可以借助redis的ZSet进行热点数据的排序。

    5、分布式锁
    这个主要利用redis的setnx命令进行，setnx："set if not exists"就是如果不存在则成功设置缓存同时返回1，否则返回0，
        因为我们服务器是集群的，定时任务可能在两台机器上都会运行，所以在定时任务中首先通过setnx设置一个lock，如果成功设置则执行，
        如果没有成功设置，则表明该定时任务已执行。 当然结合具体业务，我们可以给这个lock加一个过期时间，防止死锁的出现。

    6、分布式的集中存储
    分布式session、分布式id的集中存储之地。

21、服务器响应比较慢，接口慢？你怎么排查，或者列出你认为可能出现的问题点？
    第一步，检查网络
        ping命令检查网络域名解析是否正常，ping服务器的延迟是否过大，如果过大可以检查Ip是否冲突，或者交换机网线是否正常插好，
        通过nmon还可以查看网络流量，一般用的千兆交换机理论速率是1000/8=125MB每秒，但是这理论峰值一般都无法达到，
        所以如果网络流量达到了80~100MB每秒则可以判定瓶颈在交换机上，也可以用telnet来查看端口访问是否正常。
        通过这些方式，首先排除网络可能出现的问题

    第二步，检查服务器内存
        如果请求响应速度慢，一般跟内存关联比较大，通过free -m, vmstat 1，nmon工具等方式判断内存资源是否紧缺

    第三步，查看CPU负载
        可以通过sar、vmstat、top、nmon等工具或命令判断cpu是否过载，如果没有问题那就进行第四步

    第四步，检查磁盘IO
        可以通过iostat 1、vmstat 、nmon等命令检查磁盘的读写，如果没有问题，linux系统自身的性能问题基本排除

    第五步，抓取进程堆栈信息
        通过jstack -l pid | tee -a out.log 将pid的堆栈信息抓取出来，放到out.log的文件中分析，看是在java进程的哪一步耗时较大，然后针对那部分代码进行优化

    第六步、如果单进程没问题、思考点：
        1死锁、资源抢占
        2网络攻击
        3增加CDN、多级缓存
        4数据量过大，使用ES搜索

22、JVM调优介绍
    1查看正在运行中jvm参数是否开启或其值：
        jps :查看后台进程，可以得到进程编号
        jinfo -flag :配置项 PID 查看运行的java程序的各种信息
        jinfo -flags PID :查看所有配置项
        例：命令行（jinfo -flag PrintGCDetails PID） 输出-> -XX:+PrintGCDetails

    2查看所有配置项初始默认值、配置项修改更新值、常用配置：
        java -XX:+PrintFlagsInitial
        java -XX:+PrintFlagsFinal
        java -XX:+PrintCommandLineFlags

    3
    标配参数：
        -version 、 -help
    X参数：
        -Xint解释执行 、-Xcomp编译执行 、 -Xmixed混合模式（先编译后执行）
    XX参数：
        布尔类型：
            -XX:+PrintGCDetails 打印垃圾回收细节
            -XX:+UseSerialGC
        KV类型：
            -Xms <==> -XX:InitialHeapSize=8372
            -Xmx <==> -XX:MaxHeapSize=1024
            -Xss <==> -XX:ThreadStackSize=1024
            -Xmn <==> 设置年轻代大小，一般不调
            -XX:MetaspaceSize=1024m，默认20M左右
            -XX:SurvivorRation 设置新生代中eden比例，一般不调
            -XX:NewRatio 设置老年代的比例
            -XX:MaxTenuringThreshold=15 最大新生区的年龄，一般不调

    补充：1、默认最大堆内存是物理内存的1/4
        2、初始堆内存是物理内存的1/64
        3、新生代一般是堆大小1/3，老年代一般是堆大小2/3
        4、新生代中eden:S0:S1默认8:1:1
        5、MaxTenuringThreshold 范围0~15

23、反射的应用场景及优缺点？
    反射常见的应用场景这里介绍3个：
        Spring 实例化对象：当程序启动时，Spring 会读取配置文件applicationContext.xml并解析出里面所有的<bean>标签实例化到IOC容器中。
        反射 + 工厂模式：通过反射消除工厂中的多个分支，如果需要生产新的类，无需关注工厂类，工厂类可以应对各种新增的类，反射可以使得程序更加健壮。
        JDBC连接数据库：使用JDBC连接数据库时，指定连接数据库的驱动类时用到反射加载驱动类

    反射的优点：
        增加程序的灵活性：面对需求变更时，可以灵活地实例化不同对象。例如通过传入参数param决定使用哪一种类。
    缺点：
        破坏类的封装性：可以强制访问 private 修饰的信息
        性能损耗：反射相比直接实例化对象、调用方法、访问变量，中间需要非常多的检查步骤和解析步骤，JVM无法对它们优化。

24、创建进程和线程，有哪些系统调用可以用？
    在Linux中主要提供了fork、vfork、clone三个进程创建方法。

    fork创建一个进程时，子进程只是完全复制父进程的资源，复制出来的子进程有自己的task_struct结构和pid,但却复制父进程其它所有的资源。
    vfork创建的子进程与父进程共享地址空间，也就是说子进程完全运行在父进程的地址空间上，如果这时子进程修改了某个变量，这将影响到父进程。
    clone()是则可以将父进程资源有选择地复制给子进程，而没有复制的数据结构则通过指针的复制让子进程共享，
        具体要复制哪些资源给子进程，由参数列表中的clone_flags来决定。

    系统调用fork()和vfork()是无参数的，而clone()则带有参数。fork()是全部复制，vfork()是共享内存，clone()是选择复制。

25、内核或者CPU怎么把你的逻辑地址转化为物理地址？
    Linux内核里把线性地址转换成物理地址是通过页表映射来实现的。页表映射具体还可以分为二级页表、三级页表等。
    页表记录了逻辑页与物理页帧的对应关系，实现从页号到物理块号的地址映射。然后cpu通过物理基地址和页内偏移即可得到物理地址。

26、MMU是什么？TLB是什么？
    MMU
        1）将线性地址映射为物理地址
        2）提供硬件机制的内存访问授权（把不同的进程映射到独立的物理地址）
    TLB
        转译后备缓冲器，也被翻译为页表缓存、转址旁路缓存，为CPU的一种缓存，由存储器管理单元用于改进虚拟地址到物理地址的转译速度

27、操作系统里的I/O模型？
    阻塞IO、非阻塞IO、 IO多路复用、信号驱动式IO、异步IO。

28、SELECT、POLL、EPOLL是NIO还是BIO的模型？是同步调用还是异步调用？
    select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），
    能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，
    也就是说这个读写过程是阻塞的（可能通过while循环来检测内核将数据准备的怎么样了， 而不是属于内核的一种通知用户态机制），
    仍然需要read、write去读写数据。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。
    即异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

29、请求重传ARQ分类？
    传统自动重传请求分成为三种，即停等式(stop-and-wait）ARQ，回退n帧（go-back-n）ARQ，以及选择性重传（selective repeat）ARQ。
    后两种协议是滑动窗口技术与请求重发技术的结合，由于窗口尺寸开到足够大时，帧在线路上可以连续地流动，因此又称其为连续ARQ协议。
    三者的区别在于对于出错的数据报文的处理机制不同。三种ARQ协议中，复杂性递增，效率也递增。

    停等式ARQ：
        在停等式ARQ中，数据报文发送完成之后，发送方等待接收方的状态报告，如果状态报告报文发送成功，发送后续的数据报文，否则重传该报文。
        发送窗口和接收窗口大小均为1，发送方每发送一帧之后就必须停下来等待接收方的确认返回，仅当接收方确认正确接收后再继续发送下一帧。
        该方法所需要的缓冲存储空间最小，缺点是信道效率很低。

    回退n帧的ARQ
        发信侧不用等待收信侧的应答，持续的发送多个帧，假如发现已发送的帧中有错误发生，那么从那个发生错误的帧开始及其之后所有的帧全部再重新发送。

    选择性重传ARQ
        发信侧不用等待收信侧的应答，持续的发送多个帧，假如发现已发送的帧中有错误发生，那么发信侧将只重新发送那个发生错误的帧。

30、请求重传报文的是发送端还是接收端?
    当数据包没有成功被接收端接收时，接收端不发送ACK包，发送端将继续等待一段时间并重新发送数据包.直到接收到接收端发来的ACK。

31、TCP连接的SOCKET编程，会用到哪些系统调用和函数？
    socket（）：创建套接字。
    bind（）：指定本地地址。一旦创建了一个套接字，服务器就必须使用bind（）系统调用为套接字建立一个本地地址。
    connect（）：将套接字连接到目的地址。初始创建的套接字并未与任何外地目的地址关联。
        客户机可以调用connect（）为套接字绑定一个永久的目的地址，将它置于已连接状态。
    listen（）：设置等待连接状态。listen函数是用来设置监听连接的句柄和队列，当listen函数执行完成以后，服务端就已经可以接受客户端来的新连接了，
        新连接完成以后listen会把客户端的ip，port和连接句柄放在监听队列里面，等待accept函数来取，如果监听队列满了，listen会拒绝新来的连接。
    accept（）：接受连接请求。然后，服务器调用accept进入等待状态，直到到达一个连接请求。
    send（）/recv（）和sendto（）/recvfrom（）：发送和接收数据 。
    closesocket（）：关闭套接字。

    系统调用：
        sock_create函数：创建socket
        sock_map_fd函数：将file文件结构和fd文件描述符关联，同时将上一步返回的socket也一起绑定

32、静态代理？动态代理？
    一：静态代理是由程序员创建生成代理类，再对其编译，在程序运行之前，代理类.class文件就已经被创建了。
    二：动态代理是在程序运行时通过反射机制动态创建代理对象。

33、上亿的表插入怎么处理？
    插入速度不快：
    1、分表可以通过时间或者其他口径进行切片，原来有个项目中，有个大表是保存员工发送的消息记录，每年一亿条左右，5万员工，按年切片成表，
        每年的消息记录创建一个历史表，索引设计得当，查询速度满足要求，都保存在一台服务器上的一个mysql库运行多年。

    插入速度很快：
    1、如果你的表建了索引，除了主索引其他一定要先删掉，否则插入速度会越来越慢。数据插入完成后再建索引，重建索引也会花不少时间
    2、首先是分表+一致性hash策略，每个表的数据最好控制在百万级，
        是否要拆分服务器，这个看你的情况，如果负载很高，就得分库，然后把不同的库放到不同的服务器上了。
    3、走大数据方案，HBASE、HIVE

34、慢SQL怎么处理？
    （1）索引没起作用的情况
        MYSQL8.0
        EXPLAIN
            type 出现 ALL 或者 index 的；
            possible_keys 出现过多（待选）索引；
            key 为 NULL 的（没走索引）；
            rows 过多，或者几乎是全表的记录数的；
        各种使用不当的情况。
    （2）优化数据库结构
        1. 垂直分表，将字段很多的表分解成多个表  2. 增加字典表，防止跨节点join
    （3）分解关联查询
        将一个大的查询分解为多个小查询，在service层组合。
    （4）优化LIMIT分页
        先查询出90000条数据对应的主键id的值，然后直接通过该id的值直接查询该id后面的数据。
        select id,title from collect limit 90000,10;
        优化为：select id,title from collect where id>=(select id from collect order by id limit 90000,1) limit 10
    （5）CDN服务
        服务器比较远


35、linux查看端口占用情况
    1、lsof -i:端口号 用于查看某一端口的占用情况
        比如查看8000端口使用情况，lsof -i:8000

36、MQ核心组件
    ActiveMQ 使用时包含的基本组件各与 JMS 是相同的：

        Broker，消息代理，表示消息队列服务器实体，接受客户端连接，提供消息通信的核心服务。
        Producer，消息生产者，业务的发起方，负责生产消息并传输给 Broker 。
        Consumer，消息消费者，业务的处理方，负责从 Broker 获取消息并进行业务逻辑处理。
        exchanger，交换机。
        Queue，队列，点对点模式下特定生产者向特定队列发送消息，消费者订阅特定队列接收消息并进行业务逻辑处理。
        Message，消息体，根据不同通信协议定义的固定格式进行编码的数据包，来封装业务 数据，实现消息的传输。
        Topic，主题，发布订阅模式下的消息统一汇集地，不同生产者向 Topic 发送消息，由 Broker 分发到不同的订阅者，实现消息的广播。

37、Redis是线程安全的吗？如何保证线程安全？
    1、Redis中本身就是单线程的能够保证线程安全问题。redis是单线程运行，所以多个redis命令是一个一个执行，所以是线程安全的.
        Redis实际上是采用了线程封闭的观念，把任务封闭在一个线程，自然避免了线程安全问题。

    2、不过对于需要依赖多个redis操作的复合操作来说，依然需要锁，而且有可能是分布式锁。
        分开的两个redis命令，对于【应用】不是线程安全的，因为这两个redis命令之间会有其他命令，就像java线程不安全的i++操作，
        这个两个redis命令没有事务管理 。

    3. 可以用RPOPLPUSH或者INCR , 或者lua脚本，实现多个redis操作合为一个命令，这样就对【应用】线程安全了

38、MySQL高可用架构方案？
    MHA:















39、Redis的Sentinel高可用架构？























40、阿里巴巴Seata分布式事务解决方案？

















41、分布式任务调度？



    定时任务随着技术发展，从单线程调度到多线程调度，从单机部署到集群部署，从独立执行到多任务协同执行。

    第一阶段
    单线程调度，在Java1.5之前，基于线程的等待(sleep或wait)机制定时执行，需要开发者实现调度逻辑，单个线程(Thread)处理单个任务有些浪费，
        但是一个线程(Timer)处理多个任务容易因为某个任务繁忙导致其他任务阻塞。

    第二阶段
    线程池调度，在Java1.5开始提供ScheduledExecutorService调度线程池，调度线程池支持固定的延时和固定间隔模式，
        对于需要在某天或者某月的时间点执行就不大方便，需要计算时间间隔，转换成启动延时和固定间隔，处理起来比较麻烦。

    第三阶段
    Spring任务调度，Spring简化了任务调度，通过@Scheduled注解支持将某个Bean的方法定时执行，除了支持固定延时和固定间隔模式外，
        还支持cron表达式，使得定时任务的开发变得极其简单。 加注解@Scheduled(cron = "0/20 * * * * *")

    第四阶段
    Quartz任务调度，在任务服务集群部署下，Quartz通过数据库锁，实现任务的调度并发控制，避免同一个任务同时执行的情况。
        Quartz通过Scheduler提供了任务调度API，开发可以基于此开发自己的任务调度管理平台。

    第五阶段
    分布式任务平台，提供一个统一的平台，无需再去做和调度相关的开发，业务系统只需要实现具体的任务逻辑，自动注册到任务调度平台，
        在上面进行相关的配置就完成了定时任务的开发。

42、java和C++有什么相同点和不同点吗
    Java语言不需要程序对内存进行分配和回收。Java丢弃了C++ 中很少使用的、很难理解的、令人迷惑的那些特性，如操作符重载、多继承、自动的强制类型转换。
    特别地，Java语言不使用指针，内存的分配和回收都是自动进行的，程序员无须考虑内存碎片的问题。

43、JDK11和JDK15的新特性？
    JDK11：
    1Local Var
        在Lambda表达式中，可以使用var关键字来标识变量，变量类型由编译器自行推断。
    2HttpClient
        长期以来，如果要访问Http资源，JDK的标准库中只有一个HttpURLConnection，这个古老的API使用非常麻烦，而且已经不适用于最新的HTTP协议。
        JDK11的新的HttpClient支持HTTP/2和WebSocket，并且可以使用异步接口：
    3List API
        对于List接口，新增了一个of(T...)接口，用于快速创建List对象：List<String> list = List.of("Java", "Python", "Ruby");

    JDK15：
    1封闭类sealed
         可以是封闭类和或者封闭接口，用来增强 Java 编程语言，防止其他类或接口扩展或实现它们。
         有了这个特性，意味着以后不是你想继承就继承，想实现就实现了，你得经过允许permits才行。
         例子：public abstract sealed class Student
                permits ZhangSan, LiSi, ZhaoLiu {
                ...

            }

    2准备禁用和废除偏向锁
        在 JDK 15 中，默认情况下禁用偏向锁（Biased Locking），并弃用所有相关的命令行选项。
        后面再确定是否需要继续支持偏向锁，国为维护这种锁同步优化的成本太高了。

    3ZGC垃圾回收器 功能转正
        ZGC是一个可伸缩、低延迟的垃圾回收器。默认仍然是 G1。

44.CMS会产生什么问题？
    内存碎片（原因是采用了标记-清除算法）
    对 CPU 资源敏感（原因是并发时和用户线程一起抢占 CPU）
    浮动垃圾：在并发标记阶段产生了新垃圾不会被及时回收，而是只能等到下一次GC

45.CMS中产生的碎片有什么方法解决吗?
    CMS是一款基于“标记-清除”算法实现的收集器，如果读者对前面这部分介绍还有印象的话，就可能想到这意味着收集结束时会有大量空间碎片产生。
        空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很多剩余空间，但就是无法找到足够大的连续空间来分配当前对象，
        而不得不提前触发一次Full GC的情况。

    虚拟机设计者们还提供了另外一个参数-XX：CMSFullGCsBefore-Compaction（此参数从JDK 9开始废弃），
        这个参数的作用是要求CMS收集器在执行过若干次（数量由参数值决定）不整理空间的Full GC之后，
        下一次进入Full GC前会先进行碎片整理（默认值为0，表示每次进入Full GC时都进行碎片整理）。

46、Redis集群的全量同步和增量同步是通过什么实现的？
    全量同步： master执行bgsave生成rdb数据快照发送给Slave
    增量同步：
        从服务器 每秒钟 向从服务器发送REPLCONF ACK <replication_offset>命令来做心跳检测，以及告诉主节点自己的复制偏移量。
        主服务器若发现从服务器的复制偏移量小于自己的，根据从服务器发过来的offset，在复制积压缓冲区中找到offset之后的数据，并将其发给从节点执行就可以了。

47、CurrentHashMap的size函数？
    在实际的项目过程中，我们通常需要获取集合类的长度， 那么计算 ConcurrentHashMap 的元素大小就是一个有趣的问题，因为他是并发操作的，
        就是在你计算 size 的时候，它还在并发的插入数据，可能会导致你计算出来的 size 和你实际的 size 有差距。

    众所周知，concurrenthashmap有很多个segments，首先遍历segments将每个segment的count加起来作为整个concurrenthashMap的size。
        如果没有并发的情况下这自然就可以了，但这是多线程的，如果前脚统计完后脚有变化了，这就不准确了，源码中引入了modCount和两次比较来实现size的确认。
    1.进行第一遍遍历segments数组，将每个segemnt的count加起来作为总数，期间把每个segment的modCount加起来sum作为结果是否被修改的判断依据。
        这里需要提一下modCount，这个是当segment有任何操作都会进行一次增量操作，代表的是对Segment中元素的数量造成影响的操作的次数，
        这个值只增不减！！只增不减很重要，这样就不会出现一个segment+1，导致modcount+1,而另一个segment-1，即modcount-1 ,从而在统计所有的时候modcount没有变化。
    2.size操作就是遍历了两次所有的Segments，每次记录Segment的modCount值，然后将两次的modCount进行比较，如果相同，则表示期间没有发生过写入操作，
        就将原先遍历的结果返回，如果不相同，则把这个过程再重复做一次，如果再不相同，则就需要将所有的Segment都锁住，然后一个一个遍历了。
    3.而之所以之所以要先不加锁进行判断，道理很明显，就是不希望因为size操作获取这么多锁，因为获取锁不光占用资源，
        也会影响其他线程对ConcurrentHash的使用，影响并发情况下程序执行的效率。使用锁要谨慎！

    总结：在 JDK1.7 中，
        第一种方案他会使用不加锁的模式去尝试多次计算 ConcurrentHashMap 的 size，最多三次，
            比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的。
        第二种方案是如果第一种方案不符合，他就会给每个 Segment 加上锁，然后计算 ConcurrentHashMap 的 size 返回。

            JDK1.8 size
            是通过对 baseCount 和 counterCell 进行 CAS 计算，最终通过 baseCount 和 遍历 CounterCell 数组得出 size。


48.newCachedThreadPool的实现原理？
    newCachedThreadPool创建一个可缓存线程池，用于处理大量短时间工作任务的线程池。
        1）核心线程数为0；
        2）最大线程数为Interger.MAX_VALUE，即0x7fffffff（2147483647）
        3）线程空闲时长为60秒，如果空闲超过60秒，则线程将被终止，并移出缓存。
    该线程池，使用J.U.C的SynchronousQueue阻塞队列，该队列具有以下几个特性：
        1）SynchronousQueue没有容量。与其他BlockingQueue不同，SynchronousQueue是一个不存储元素的BlockingQueue。
            每一个put操作必须要等待一个take操作，否则不能继续添加元素，反之亦然。
        2）因为没有容量，所以对应 peek, contains, clear, isEmpty ... 等方法其实是无效的。
            例如clear是不执行任何操作的，contains始终返回false,peek始终返回null。

49.红黑树和平衡二叉树的区别？跳表的查找时间复杂度？
    红黑树放弃了追求完全平衡，追求大致平衡，在与平衡二叉树的时间复杂度相差不大的情况下，保证每次插入最多只需要三次旋转就能达到平衡，实现起来也更为简单。
        平衡二叉树追求绝对平衡，条件比较苛刻，实现起来比较麻烦，每次插入新节点之后需要旋转的次数不能预知。

    最高级索引 h 满足 2 = n/2^h，即 h = log2n - 1，最高级索引 h 为索引层的高度加上原始数据一层，跳表的总高度 h = log2n。所以查找的时间复杂度是常数*log2n
50.新生代转换为老年代有几种情况？
    1.Eden区满时，进行Minor GC
        当Eden和一个Survivor区中依然存活的对象无法放入到Survivor中，则通过分配担保机制提前转移到老年代中。

    2.对象体积太大, 新生代无法容纳
        -XX:PretenureSizeThreshold即对象的大小大于此值, 就会绕过新生代, 直接在老年代分配, 此参数只对Serial及ParNew两款收集器有效。

    3.长期存活的对象将进入老年代
        虚拟机对每个对象定义了一个对象年龄（Age）计数器。当年龄增加到一定的临界值时，就会晋升到老年代中，该临界值由参数：-XX:MaxTenuringThreshold来设置。
            如果对象在Eden出生并在第一次发生MinorGC时仍然存活，并且能够被Survivor中所容纳的话，则该对象会被移动到Survivor中，并且设Age=1；
            以后每经历一次Minor GC，该对象还存活的话Age=Age+1。

    4.动态对象年龄判定
        虚拟机并不总是要求对象的年龄必须达到MaxTenuringThreshold才能晋升到老年代，如果在Survivor区中相同年龄（设年龄为age）
            的对象的所有大小之和超过Survivor空间的一半，年龄大于或等于该年龄（age）的对象就可以直接进入老年代，
            无需等到MaxTenuringThreshold中要求的年龄。

51.TCP的TIME_WAIT和CLOSE_WAIT介绍下？如果系统中出现了大量的CLOSE_WAIT怎么排查？
    TIME_WAIT : 2MSL
    CLOSE_WAIT : 服务端收到FIN信号后进入该状态，该状态即为服务端处理完响应逻辑代码的阶段？

    通常，CLOSE_WAIT 状态在服务器停留时间很短，如果你发现大量的 CLOSE_WAIT 状态，那么就意味着被动关闭的一方没有及时发出 FIN 包，一般有如下几种可能：
        1程序问题：如果代码层面忘记了 close 相应的 socket 连接，那么自然不会发出 FIN 包，从而导致 CLOSE_WAIT 累积；
            或者代码不严谨，出现死循环之类的问题，导致即便后面写了 close 也永远执行不到。
        2响应太慢或者超时设置过小：如果连接双方不和谐，一方不耐烦直接 timeout，另一方却还在忙于耗时逻辑，就会导致 close 被延后。
            响应太慢是首要问题，不过换个角度看，也可能是 timeout 设置过小。

52.往redis存对象，使用String好还是Hash结构好，分析优缺点？
    当如下情况时redis的hash类型，底层是用ziplist编码的：
        哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节；
        哈希对象保存的键值对数量小于 512 个；
    不满足上述情况时，redis的hash类型，底层编码格式为hashtable。

    如果你的业务类型中对于缓存的读取缓存的场景更多，并且更新缓存不频繁（或者每次更新都更新json数据中的大多数key），那么选择string类型作为存储方式会比较好。
    如果你的业务类型中对于缓存的更新比较频繁（特别是每次只更新少数几个键）时， 或者我们每次只想取json数据中的少数几个键值时，我们选择hash类型作为我们的存储方式会比较好。.

53.sentinel模式故障转移怎么做到外部无感知？
    故障转移后客户端无法感知将无法保证正常的使用。所以，实现客户端高可用的步骤如下:
        1.客户端获取sentinel节点集合
        2.客户端通过sentinel get-master-addr-by-name master-name这个api来获取对应主节点信息
        3.客户端验证当前获取的“主节点”是真正的主节点，这样的目的是为了防止故障转移期间主节点的变化
        4.客户端保持和sentinel节点集合的联系，即订阅sentinel节点相关频道，时刻获取关于主节点的相关信息

    从上面的模型可以看出，Redis sentinel客户端只有在初始化和切换主节点时需要和sentinel进行通信来获取主节点信息，
        所以在设计客户端时需要将sentinel节点集合考虑成配置（相关节点信息和变化）发现服务。

54.介绍下java线程join方法
    join方法是实现线程同步，可以将原本并行执行的多线程方法变成串行执行的。源码还是比较容易理解的，其实就是调用了现场wait方法实现线程同步的

    join方法的作用是，举个例子，在A线程里调B线程的join方法时，要先B线程执行完成，然后才会继续执行A线程
        上面调join方法是不加参数的，也可以加上参数，比如线程A.join(10)；，就是说线程A执行10s后，继续执行B线程
        注意：join时间参数缺省的情况，默认是0，也就是说join()等同于join(0);0不是表示执行0s，而是表示要A线程执行完成才继续执行B线程的意思。

55.线程池用到哪些阻塞队列?
    线程池	阻塞队列
    FixedThreadPool	                LinkedBlockingQueue
    SingleThreadExecutor	        LinkedBlockingQueue
    CachedThreadPool	            SynchronousQueue
    ScheduledThreadPool	            DelayedWorkQueue
    SingleThreadScheduledExecutor	DelayedWorkQueue

    LinkedBlockingQueue
        第一种阻塞队列是 LinkedBlockingQueue，它的容量是 Integer.MAX_VALUE，是一个非常大的值，可以认为是无界队列。
        FixedThreadPool 和 SingleThreadExecutor 线程池的线程数是固定的，所以没有办法增加特别多的线程来处理任务，
            这时就需要 LinkedBlockingQueue 这样一个没有容量限制的阻塞队列来存放任务。

    SynchronousQueue
        第二种阻塞队列是 SynchronousQueue，对应的线程池是 CachedThreadPool。线程池 CachedThreadPool 的最大线程数是 Integer.MAX_VALUE，可以理解为线程数是可以无限扩展的。
        CachedThreadPool 和上一种线程池 FixedThreadPool 的情况恰恰相反，FixedThreadPool 的情况是阻塞队列的容量是无限的，而这里 CachedThreadPool 是线程数可以无限扩展，
            所以 CachedThreadPool 线程池并不需要一个任务队列来存储任务，因为一旦有任务被提交就直接转发给线程或者创建新线程来执行，而不需要另外保存它们。

        我们自己创建使用 SynchronousQueue 的线程池时，如果不希望任务被拒绝，那么就需要注意设置最大线程数要尽可能大一些，
            以免发生任务数大于最大线程数时，没办法把任务放到队列中也没有足够线程来执行任务的情况。

    DelayedWorkQueue
        第三种阻塞队列是DelayedWorkQueue，它对应的线程池分别是 ScheduledThreadPool 和 SingleThreadScheduledExecutor，
            这两种线程池的最大特点就是可以延迟执行任务，比如说一定时间后执行任务或是每隔一定的时间执行一次任务。

        DelayedWorkQueue 的特点是内部元素并不是按照放入的时间排序，而是会按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构。
            之所以线程池 ScheduledThreadPool 和 SingleThreadScheduledExecutor 选择 DelayedWorkQueue，是因为它们本身正是基于时间执行任务的，而延迟队列正好可以把任务按时间进行排序，方便任务的执行。

56.线程知识中Future 的作用？
    简单来说就是利用线程达到异步的效果，同时还可以获取子线程的返回值。
        我们可以把运算的过程放到子线程去执行，再通过 Future 去获取到计算结果。这样一来就可以把整个程序的运行效率提高，是一种异步的思想。

    FutureTask实现了两个接口，Runnable和Future，所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值
    典型用法是，把 Callable 实例当作 FutureTask 构造函数的参数，生成 FutureTask 的对象，
        然后把这个对象当作一个 Runnable 对象，放到线程池中或另起线程去执行，最后还可以通过 FutureTask 获取任务执行的结果

57.cpu如何寻址？
    处理器采用多级页表来进行多次查找最终找到真正的物理地址。
        由于页表是存放在内存中的，使用一级页表进行地址转换时，每次读/写数据需要访问两次内存，第一次访问一级页表获得物理地址，第二次才是真正的读/写数据；
        使用两级页表时，每次读/写数据需要访问三次内存，访问两次页表（一级页表和二级页表）获得物理地址，第三次才是真正的读/写数据。
    拿处理器访问两级页表举例说明，当处理器拿到一个需要访问内存的虚拟地址，MMU首先访问TLB Cache（近期页表的缓存），如果TLB Cache中含有能转换这个虚拟地址的描述符，
        则直接利用此描述符进行地址转换和权限检查；否则MMU访问页表（页表是在主存中）找到描述符后再进行地址转换和权限检查，并将这个描述符填入TLB Cache中，
        下次再使用这个虚拟地址时就可以直接使用TLB Cache中的地址描述符了。

58.为什么要三次握手?
    为了实现可靠数据传输， TCP 协议的通信双方， 都必须维护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。
        三次握手的过程即是通信双方相互告知序列号起始值， 并确认对方已经收到了序列号起始值的必经步骤。
        如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认。

    同时这样可以防止已失效的连接请求又传送到服务器端，因而产生错误。

59.Redis的Cluster集群模式？
    结构：                                            分配策略：







    特点：







    故障转移：







60.说说Web高可用架构？










61. 数据库sql关键字执行顺序？
    from--->.where,---->group by--->,having,--->select,--->distinct---->,union----->,order by

62.守护线程和僵尸线程

    任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on) 设置，true则是将该线程设置为守护线程，false则是将该线程设置为用户线程。
    同时，Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。

    用户线程：平时使用到的线程均为用户线程。
    守护线程：用来服务用户线程的线程，例如垃圾回收线程。

    用户线程：当任何一个用户线程未结束，Java虚拟机是不会结束的。
    守护线程：如何只剩守护线程未结束，Java虚拟机结束。

63.redis的数据结构底层？
    string：
        我们知道Redis是由C语言编写的。Redis由于各种原因，并没有直接使用了C语言的字符串结构，而是对其做了一些封装，
            得到了自己的简单动态字符串(simple dynamic string, SDS)的抽象类型。Redis中，默认以SDS作为自己的字符串表示。只有在一些字符串不可能出现变化的地方使用C字符串。

        SDS与C字符串的区别
        1、常数复杂度获取字符串长度
            而SDS结构中本身就有记录字符串长度的len属性，所有复杂度为O(1)。
            Redis将获取字符串长度所需的复杂度从O(N)降到了O(1)，确保获取字符串长度的工作不会成为Redis的性能瓶颈
        2、杜绝缓冲区溢出，减少修改字符串时带来的内存重分配次数
            SDS实现了空间预分配和惰性空间释放两种优化的空间分配策略，解决了字符串拼接和截取的空间问题**，修改字符串长度N次最多会需要执行N次内存重分配

    hash：
        ziplist+hashtable
        这两种数据结构我们之前都有讲解，hash对象只有同时满足以下条件，才会采用ziplist编码：
           1 hash对象保存的键和值字符串长度都小于64字节
           2 hash对象保存的键值对数量小于512 ziplist存储的结构如下

    list：
        压缩列表ziplist+双向链表linkedlist
            ziplist 是一个特殊的双向链表
            特殊之处在于：没有维护双向指针:prev next；而是存储上一个 entry的长度和 当前entry的长度，通过长度推算下一个元素在什么地方。
            牺牲读取的性能，获得高效的存储空间，因为(简短字符串的情况)存储指针比存储entry长度 更费内存。这是典型的“时间换空间”。

    set：
        Set底层用两种数据结构存储，一个是hashtable，一个是inset。
        其中hashtable的key为set中元素的值，而value为null

        inset为可以理解为数组，使用inset数据结构需要满足下述两个条件：
            元素个数不少于默认值512
            set-max-inset-entries 512
            元素可以用整型表示
        inset结构体定义如下：
            typedef struct intset {
                uint32_t encoding;  // 编码方式，一个元素所需要的内存大小
                uint32_t length;    // 集合长度
                int8_t contents[];  // 集合数组，整数集合的每个元素在数组中按值的大小从小到大排序，且不包含重复项
            } intset;
        inset查询方式一般采用二分查找法，实际查询复杂度也就在log(n)，你会发现到redis是在数据量少的情况下才会用到这个数据结构，
            插入删除O(n)在数据量少的情况下移动数据可以用到CPU向量化执行的特性，特别快，在数据量大的话性能退化选用其他数据结构

    zset：ziplist+跳表



64.线程创建方式？
    1.继承Thread类创建线程，首先继承Thread类，重写run()方法，在main()函数中调用子类实实例的start()方法。
        public class ThreadDemo extends Thread {
            @Override
            public void run() {
                System.out.println(Thread.currentThread().getName() + " run()方法正在执行");
            }
        }
        public class TheadTest {
            public static void main(String[] args) {
                ThreadDemo threadDemo = new ThreadDemo();
                threadDemo.start();
                System.out.println(Thread.currentThread().getName() + " main()方法执行结束");
            }
        }
    2.实现Runnable接口创建线程：首先创建实现Runnable接口的类RunnableDemo，重写run()方法；
        创建类RunnableDemo的实例对象runnableDemo，以runnableDemo作为参数创建Thread对象，调用Thread对象的start()方法。
        public class RunnableDemo implements Runnable {
            @Override
            public void run() {
                System.out.println(Thread.currentThread().getName() + " run()方法执行中");
            }
        }
        public class RunnableTest {
            public static void main(String[] args) {
                RunnableDemo  runnableDemo = new RunnableDemo ();
                Thread thread = new Thread(runnableDemo);
                thread.start();
                System.out.println(Thread.currentThread().getName() + " main()方法执行完成");
        }
    3.使用Callable和Future创建线程：
        1. 创建Callable接口的实现类CallableDemo，重写call()方法。
        2. 以类CallableDemo的实例化对象作为参数创建FutureTask对象。
        3. 以FutureTask对象作为参数创建Thread对象。
        4. 调用Thread对象的start()方法。
        class CallableDemo implements Callable<Integer> {
            @Override
            public Integer call() {
                System.out.println(Thread.currentThread().getName() + " call()方法执行中");
                return 0;
            }
        }
         class CallableTest {
            public static void main(String[] args) throws ExecutionException, InterruptedException {
                FutureTask<Integer> futureTask = new FutureTask<Integer>(new CallableDemo());
                Thread thread = new Thread(futureTask);
                thread.start();
                System.out.println("返回结果 " + futureTask.get());
                System.out.println(Thread.currentThread().getName() + " main()方法执行完成");
            }
        }
    4.使用线程池例如用Executor框架： Executors可提供四种线程池.
        class ThreadDemo extends Thread {
            @Override
            public void run() {
                System.out.println(Thread.currentThread().getName() + "正在执行");
            }
        }
        class TestFixedThreadPool {
            public static void main(String[] args) {
                //创建一个可重用固定线程数的线程池
                ExecutorService pool = Executors.newFixedThreadPool(2);
                //创建实现了Runnable接口对象，Thread对象当然也实现了Runnable接口
                Thread t1 = new ThreadDemo();
                Thread t2 = new ThreadDemo();
                //将线程放入池中进行执行
                pool.execute(t1);
                pool.execute(t2);
                //关闭线程池
                pool.shutdown();
            }
        }

65.同步方法和同步块，哪个是更好的选择？
   同步块是更好的选择，因为它不会锁住整个对象（当然你也可以让它锁住整个对象）。
   同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。

66.重量级锁的底部Monitor实现原理？
    Monitor数据结构的 _owner、_WaitSet和_EntryList 字段比较重要，它们之间的转换关系如下图
    _owner        = NULL; //指向持有ObjectMonitor对象的线程地址
    _count        = 0; //锁的计数器，获取锁时count数值加1，释放锁时count值减1，直到
    _WaitSet      = NULL; //处于wait状态的线程，会被加入到_WaitSet
    _EntryList    = NULL ; //处于等待锁block状态的线程，会被加入到该列表
    _recursions   = 0; //锁的重入次数


    从上图可以总结获取Monitor和释放Monitor的流程如下：
    1当多个线程同时访问同步代码块时，首先会进入到EntryList中，然后通过CAS的方式尝试将Monitor中的owner字段设置为当前线程，
        同时count加1，若发现之前的owner的值就是指向当前线程的，recursions也需要加1。如果CAS尝试获取锁失败，则进入到EntryList中。
    2当获取锁的线程调用wait()方法，则会将owner设置为null，同时count减1，recursions减1，当前线程加入到WaitSet中，等待被唤醒。
    3当前线程执行完同步代码块时，则会释放锁，count减1，recursions减1。当recursions的值为0时，说明线程已经释放了锁。

    之前提到过一个常见面试题，为什么wait()、notify()等方法要在同步方法或同步代码块中来执行呢，
        是因为wait()、notify()方法需要借助ObjectMonitor对象内部方法来完成。

67.synchronized关键字的底层原理？
    同步代码块:
        是由monitorenter 和 monitorexit 指令完成的，其中monitorenter指令所在的位置是同步代码块开始的位置，
            第一个monitorexit 指令是用于正常结束同步代码块的指令，第二个monitorexit 指令是用于异常结束时所执行的释放Monitor指令。
    同步方法原理:
        没有monitorenter 和 monitorexit 这两个指令了，而在查看该方法的class文件的结构信息时发现了Access flags后边的synchronized标识，
        该标识表明了该方法是一个同步方法。Java虚拟机通过该标识可以来辨别一个方法是否为同步方法，如果有该标识，线程将持有Monitor，在执行方法，最后释放Monitor。

    总结：Java虚拟机是通过进入和退出Monitor对象来实现代码块同步和方法同步的，代码块同步使用的是monitorenter 和 monitorexit 指令实现的，
        而方法同步是通过Access flags后面的标识来确定该方法是否为同步方法。
68.ConCurrentHashMap的put()方法？
    JDK1.7中的put()方法：
    先计算出key的hash值，利用hash值对segment数组取余找到对应的segment对象。
    尝试获取锁，失败则自旋直至成功，获取到锁，通过计算的hash值对hashentry数组进行取余，找到对应的entry对象。
    遍历链表，查找对应的key值，如果找到则将旧的value直接覆盖，如果没有找到，则添加到链表中。（JDK1.7是插入到链表头部，JDK1.8是插入到链表尾部，这里可以思考一下为什么这样）
    JDK1.8中的put()方法:

    计算key值的hash值，找到对应的Node，如果当前位置为空则可以直接写入数据。
    利用CAS尝试写入，如果失败则自旋直至成功，如果都不满足，则利用synchronized锁写入数据。

69.ConcurrentHashMap迭代器是强一致性还是弱一致性？
    与HashMap不同的是，ConcurrentHashMap迭代器是弱一致性。

    这里解释一下弱一致性是什么意思，当ConcurrentHashMap的迭代器创建后，会遍历哈希表中的元素，在遍历的过程中，哈希表中的元素可能发生变化，
        如果这部分变化发生在已经遍历过的地方，迭代器则不会反映出来，如果这部分变化发生在未遍历过的地方，迭代器则会反映出来。
        换种说法就是put()方法将一个元素加入到底层数据结构后，get()可能在某段时间内还看不到这个元素。

    这样的设计主要是为ConcurrenthashMap的性能考虑，如果想做到强一致性，就要到处加锁，性能会下降很多。
        所以ConcurrentHashMap是支持在迭代过程中，向map中添加元素的，而HashMap这样操作则会抛出异常。

70.ConCurrentHashMap 的key，value是否可以为null?
    不能。ConCurrentHashMap中的key和value为null会出现空指针异常，而HashMap中的key和value值是可以为null的。

    原因如下：ConCurrentHashMap是在多线程场景下使用的，如果ConcurrentHashMap.get(key)的值为null，那么无法判断到底是key对应的value的值为null还是不存在对应的key值。
        而在单线程场景下的HashMap中，可以使用containsKey(key)来判断到底是不存在这个key还是key对应的value的值为null。
        在多线程的情况下使用containsKey(key)来做这个判断是存在问题的，因为在containsKey(key)和ConcurrentHashMap.get(key)两次调用的过程中，key的值可能已经发生了改变。
        即你一开始get方法获取到null之后，再去调用containsKey方法，没法确保get方法和containsKey方法之间，没有别的线程来捣乱，刚好把你要查询的对象设置了进去或者删除掉了。


71.MySQL主从同步的一致性怎么保证？MySQL主从同步多长时间同步一次？
    一般情况保证最终一致性即可，但有些场景必须保证强一致性，可用全同步复制。
    1、异步模式（默认方式）
        异步模式下，主节点执行完客户端提交的事务后立即提交事务并返回给客户端，并不关心 log dump 线程是否成功地将将此次事务写进 binglog 并且发送给从库。
            假如执行事务的主线程提交事务后，log dump 线程还未来得及写入 binlog，此时系统宕机，则会造成 binglog 中没有保存刚才提交的事务，造成主从数据不一致。

        优点：异步模式下，主线程不用关系同步操作，性能最好。
        缺点：可能导致主从数据的不一致。
    2、半同步复制
        半同步方式，当主库在执行完客户端提交的事务后不是立即提交事务，而是等待 log dump 线程将此次事务同步到binlog 发送给从库，
            并且至少一个从库成功保存到其relay log中，此时主库的才提交事务并返回客户端。

        优点：相比于异步模式，半同步方式一定程度上保证了数据同步的可靠性。
        缺点：增加了主库响应客户端的延时，延时至少为一个 TCP/IP 的往返时间，即 binglog 发送给从库至收到从库的响应时间。
    3、全同步复制（类似于分布式事务二阶段提交的思想）
        全同步方式，当主库在执行完客户端提交的事务后，必须等待此次的binlog发送给从库，并且所有从库成功地执行完该事务后，主库才能返回客户端。其与半同步复制的区别如下：
            半同步下，主库等待binlog写入到从库的relay log即可返回，全同步方式下，必须等到从库执行事务成功。
            半同步下，至少一个从库响应后主库即可返回客户端，全同步下必须等待所有的从库返回。
        优点：对比半同步复制方式，全同步复制方式数据一致性的可靠性进一步提高
        缺点：执行事务时，主库需要等待所有的从库执行成功后才能返回，所以会大大提高主库的响应时间。

    默认一分钟同步一次

72.僵尸进程和孤儿进程？
    一：僵尸进程（有害）
    　　一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程
        我们知道在unix/linux中，正常情况下子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,
            即父进程永远无法预测子进程到底什么时候结束，如果子进程一结束就立刻回收其全部资源，那么在父进程内将无法获取子进程的状态信息。
            因此，UNⅨ提供了一种机制可以保证父进程可以在任意时刻获取子进程结束时的状态信息：
            1、在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。
                但是仍然为其保留一定的信息（包括进程号the process ID，退出状态the termination status of the process，运行时间the amount of CPU time taken by the process等）
            2、直到父进程通过wait / waitpid来取时才释放. 但这样就导致了问题，如果进程不调用wait / waitpid的话，那么保留的那段信息就不会释放，
                其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程.
                此即为僵尸进程的危害，应当避免。
    　　任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。
            这是每个子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。
            如果父进程能及时处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。
            如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。
    二：孤儿进程（无害）
    　　孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
    　　孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程专门负责处理孤儿进程的善后工作。
            每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。
            这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。

73.为什么linux为什么要有父子进程？
    除了第一个进程，任何进程都是fork出来的。子进程fork出父进程的一个副本。
    为了方便管理，因为子进程会继承父进程的属性和权限，而父进程也可以系统地管理子进程。这样不管是从安全性还是管理难易程度都是非常好的。

74.进程的创建过程
   一旦操作系统发现了要求创建新进程的事件后，便调用进程创建原语create()按下述步骤创建一个新进程。
       1） 申请空白PCB。为新进程申请获得唯一的数字标识符，并从PCB集合中索取一个空白PCB。

       2） 为新进程分配资源。为新进程的程序和数据以及用户栈分配必要的内存空间。显然，此时操作系统必须知道新进程所需要的内存大小。

       3） 初始化进程控制块。PCB的初始化包括：
            ①初始化标识信息，将系统分配的标识符和父进程标识符，填入新的PCB中。
            ②初始化处理机状态信息，使程序计数器指向程序的入口地址，使栈指针指向栈顶。
            ③初始化处理机控制信息，将进程的状态设置为就绪状态或静止就绪状态，对于优先级，通常是将它设置为最低优先级，除非用户以显式的方式提出高优先级要求。

       4） 将新进程插入就绪队列，如果进程就绪队列能够接纳新进程，便将新进程插入到就绪队列中。

75.tcp的Accept队列。
    TCP服务端会维护两个队列，一个是SYN队列（未连接队列），一个是Accept队列（已连接队列）。
    当收到客户端发来的SYN报文后，把该连接放入SYN队列中，然后回复SYN+ACK给客户端。
    当服务端收到了客户端的第三次握手（ACK）后，就把这个连接放入Accept队列中，此时连接建立完成，三次握手完成。
    当应用程序调用Accept（）函数时，内核会从Accept队列中选择一个正确的连接取出返回给应用程序。

76.socket编程中的accept()方法作用，会引起惊群吗？
      accept()：在一个socket 接受一个连接
      accept函数主要用于服务器端，一般位于listen函数之后，默认会阻塞进程，直到有一个客户请求连接，建立好连接后，
        它返回的一个新的套接字 socketfd_new ，此后，服务器端即可使用这个新的套接字socketfd_new与该客户端进行通信，而sockfd 则继续用于监听其他客户端的连接请求。

    惊群效应是什么惊群效应（thundering herd）是指多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），如果等待的这个事件发生，
        那么他就会唤醒等待的所有进程（或者线程），但是最终却只能有一个进程（线程）获得这个时间的“控制权”，对该事件进行处理，
        而其他进程（线程）获取“控制权”失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群效应。

    一般都是socket的accept()会导致惊群，很多个进程都block在server socket的accept()，一但有客户端进来，所有进程的accept()都会返回，但是只有一个进程会读到数据，就是惊群。
    Linux 2.6 版本之前，监听同一个 socket 的进程会挂在同一个等待队列上，当请求到来时，会唤醒所有等待的进程。
    Linux 2.6 版本之后，Linux解决accept惊群的方法是，引入一个排他性标志位（WQ_FLAG_EXCLUSEVE），
        用户进程 task 对 listen socket 进行 accept 操作，如果这个时候如果没有新的 connect 请求过来，用户进程 task 会阻塞睡眠在 listent fd 的睡眠队列上。
        这个时候，用户进程 Task 会被设置 WQ_FLAG_EXCLUSIVE 标志位，并加入到 listen socket 的睡眠队列尾部
        (这里要确保所有不带 WQ_FLAG_EXCLUSIVE 标志位的 non-exclusive waiters 排在带 WQ_FLAG_EXCLUSIVE 标志位的 exclusive waiters 前面)。
        根据前面的唤醒逻辑，一个新的 connect 到来，内核只会唤醒一个用户进程 task 就会退出唤醒过程，从而不存在了"惊群"现象。

77.hashmap链表转换红黑树？为什么选择8？
    当链表长度大于或等于阈值（默认为 8）的时候，如果同时还满足容量大于或等于 MIN_TREEIFY_CAPACITY（默认为 64）的要求，就会把链表转换为红黑树。
    同样，后续如果由于删除或者其他原因调整了大小，当红黑树的节点小于或等于 6 个以后，又会恢复为链表形态。

    通常如果 hash 算法正常的话，那么链表的长度也不会很长，那么红黑树也不会带来明显的查询时间上的优势，反而会增加空间负担。
    所以通常情况下，并没有必要转为红黑树，所以就选择了概率非常小，小于千万分之一概率，也就是长度为 8 的概率，把长度 8 作为转化的默认阈值。

78.select、poll、epoll区别？
    1、select连接数有限制，最大处理连接数不超过1024，epoll连接数很大。
    2、select是线性轮询，总连接数很大时性能下降严重。epoll是基于回调callback的事件驱动，不会随着FD数目的增加效率下降。
    3、select数组，poll链表，epoll红黑树
    4、每次调用selcet、poll每次调用都要把fd集合从用户态拷入内核态。epoll只要拷贝一次。

79.MySQL查询一条语句的执行流程？MySQL服务的构成？
    执行流程：


    构成：
        1 连接层
            提供链接协议(socket,tcp/ip) #这里的socket也不是网络连接的socket,mysql的socket连接只能连接本地
            验证用户的合法性(用户名,密码,白名单)
            提供一个专用连接线程(接收sql,返回结果,将sql语句交给sql层继续处理)
        2 SQL层
            接收到sql语句（判断语法、判断语义、判断语句类型[DML、DDL、DCL、DQL]）
            数据库对象授权检查
            解析SQL语句，生成多种执行计划，MySQL没法直接执行SQL语句，必须解析成执行计划，运行执行计划，最终生成如何去磁盘找数据的方式
            优化器，选择它认为成本最低的执行计划
            执行器，根据优化器的选，按照优化器建议执行sql语句，得到去哪儿找sql语句需要访问的数据：A、具体在哪个数据文件上的哪个数据页中 B、将以上结果充送给下层继续处理
            接收存储引擎层的数据，结构化成表的形式，通过连接层提供的专用线程，将表数据返回给用户
            提供查询缓存，缓存之前查询的数据，假如查询的表是一个经常变动的表，查询缓存不要设置太大， query_cache使用memcached或Redis代替
            日志记录(binlog)
        3 存储引擎层
            接收上层的执行结果
            取出磁盘文件和相应数据
            返回给sql层，结构化之后生成表格，由专用线程返回给客户端
            存储引擎用于：
                存储数据（将SQL语句做的修改转储到磁盘上）
                检索数据（把存进去的数据在提取出来）

80.SELECT(0)、SELECT 0、Select Count(0)、Select Count(1)？
    SELECT(0),是一个函数
        返回当前工作区的编号
    SELECT 0 是一个命令
        选定未被使用的且最小的可以使用的工作区为当前工作区

    Select Count(0)和Select Count(1)完全一样
    1、一般情况下，Select Count (*)和Select Count(1)两着返回结果是一样的
    2、 假如表沒有主键(Primary key), 那么count(1)比count(*)快

81.系统调用和函数调用有什么区别？
   1.使用INT和IRET指令，内核和应用程序使用的是不同的堆栈，因此存在堆栈的切换，从用户态切换到内核态，从而可以使用特权指令操控设备
   2.依赖于内核，不保证移植性
   3.在用户空间和内核上下文环境间切换，开销较大
   4. 是操作系统的一个入口点
   函数调用
   1.使用CALL和RET指令，调用时没有堆栈切换
   2.平台移植性好
   3.属于过程调用，调用开销较小
   4.一个普通功能函数的调用

82.聚簇索引和非聚簇索引的区别以及各自的优缺点？
    聚集索引,表中存储的数据按照索引的顺序存储,检索效率比普通索引高,但对数据新增/修改/删除的影响比较大
    非聚集索引,不影响表中的数据存储顺序,检索效率比聚集索引低,对数据新增/修改/删除的影响很小

83.如何打破双亲委派？哪些框架是打破了双亲委派？
    如果不想打破双亲委派模型，就重写ClassLoader类中的findClass()方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。
    而如果想打破双亲委派模型则需要重写loadClass()方法。

    典型的打破双亲委派模型的框架和中间件有tomcat与osgi。

84.线程池超过核心线程的线程会被回收，如何实现？
    阻塞队列的timeout参数
    当非核心线程去尝试从队列中获取任务时，获取不到任务会阻塞，如果超过了阻塞队列锁设置的timeout超时参数，即可认为是闲置的非核心线程，回收即可。

85.红黑树的特性？应用场景？
   （1）每个节点或者是黑色，或者是红色。
   （2）根节点是黑色。
   （3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]
   （4）如果一个节点是红色的，则它的子节点必须是黑色的。
   （5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。

   注意：
   (01) 特性(3)中的叶子节点，是只为空(NIL或null)的节点。
   (02) 特性(5)，确保没有一条路径会比其他路径长出俩倍。因而，红黑树是相对是接近平衡的二叉树。


    红黑树的应用：
    1、java8 hashmap中链表转红黑树。
        优势：时间复杂度从O(n)-->O(logn) ，且自旋开销较其他树较低（不用整体平衡）。
    2、epoll在内核中的实现，用红黑树管理事件块（文件描述符）。
        优势：
            1、因为内核态需要维护一个长久存放fd的数据结构，而fd变动十分频繁，且需要支持快速查询，且所以红黑树很适合。
            2、红黑树可以判断是否是重复的fd
    3、Java的TreeMap实现
        优势：相对与hashMap优势，内部key保持有序，且支持自定义排序比较器。
        适用场景，对数据需要排序统计


86.如何排查死锁？
    jps + jstack。使用jstack工具，是jdkk自带的线程堆栈分析工具。
    第一：在windons命令窗口，使用 jps -l





    第二：使用jstack -l 12316








87.磁盘调度算法？
    1.先到先服务
        如果访问的磁道很分散，性能上就很差，因为寻道时间过长
    2.最短寻道时间优先算法
        可能造成某些请求饥饿，原因是磁头在一小块区域来回移动。
    3.扫描算法（电梯算法）
        磁头在一个方向上移动，访问所有未完成的请求，知道磁头到达该方向上的最后一个磁道，才调换方向。
        中间部分磁道比其他部分响应的频率高，即每个磁道的响应频率存在差异。
    4.循环扫描算法
        总是按相同的方向扫描，磁道只响应一个方向上的请求，使得每个磁道的响应频率基本一致。
        只有磁头朝某个特定方向移动时，才处理磁道访问请求，复位磁头时直接快速移动至最靠边缘的磁道，返回途中不处理任何请求。
    5.LOCK与C-LOCK算法
        磁头在移动到最远的请求位置，立即反向移动。磁头不用移动到磁盘最始端和最末端才开始调换方向。
        LOCK算法，反向移动的途中会响应请求。
        C-LOCK算法，反向移动的途中不会响应请求。

88.为什么选用json序列化而不使用java的JDK序列化？
    1.jdk序列化无法跨平台。（解码端也要用java的jdk反序列化）
    2.有安全风险。（二进制文件流可能被篡改，而json可以用https：SSL加密，没有被篡改）
    3.相比于json序列化，序列更长，传输解析更慢。

89.索引选择性差导致全表搜索解决办法？
    1.通过将索引组合提高选择性（业务相关）
        select * from 护士表 where 科室 = '妇科' and 性别 = '女'。
    2.引入搜索引擎，如Es或者Solr（更换数据源）
        将护士表导入ElasticSearch，Es基于分片多线程检索，解决查询慢问题。
    3.强制使用索引（有时有奇效，以实际运行为准）
        explain select * from question force index（answer） where answer = 'A';
    4.增加缓存，提高全表扫描速度。（钞能力）（Redis同理）
        就是给更多的内存去加载,利用内存的高吞吐解决查询慢的问题
        innodb_buffer_pool_size = 16G
        innodb_buffer_poll_instances = 2;


90.查找文件里是否包含某个字符串？
    Grep 命令
        参数： -I ：忽略大小写 -c ：打印匹配的行数 -n：打印包含匹配项的行和行标 -v ：查找不包含匹配项的行

    例子： 在access.log里查找“makehtml_archives”
        grep -n makehtml_archives access.log

91.MQ的存储介质损坏，该如何处理？
    单机可使用RAID10方案存储。整个RAID0包含了所有数据，每一块数据又有相同的备份。







    RAID0是将所有数据分散存储到两块不同的硬盘上。每个RAID1硬盘大小性能相同，两块硬盘数据完全相同，一块一盘坏了可以去另一块补上。








92.本地缓存和分布式缓存优缺点？
    缓存：
        在服务端编程当中，缓存主要是指将数据库的数据加载到内存中，之后对该数据的访问都在内存中完成，从而减少了对数据库的访问。
            以及基于内存的访问速度高于磁盘的访问速度的原理，提高了数据的访问速度和程序性能。
        根据缓存是否与应用进程属于同一进程，可以将内存分为本地缓存和分布式缓存。
            本地缓存是在同一个进程内的内存空间中缓存数据，数据读写都是在同一个进程内完成；
            而分布式缓存是一个独立部署的进程并且一般都是与应用进程部署在不同的机器，故需要通过网络来完成分布式缓存数据读写操作的数据传输。

    I、本地缓存的优缺点：
        1. 访问速度快，但无法进行大数据存储
            本地缓存相对于分布式缓存的好处是，由于数据不需要跨网络传输，故性能更好，但是由于占用了应用进程的内存空间，
            如 Java 进程的 JVM 内存空间，故不能进行大数据量的数据存储。
        2. 集群的数据更新问题
            与此同时，本地缓存只支持被该应用进程访问，一般无法被其他应用进程访问，故在应用进程的集群部署当中，如果对应的数据库数据，
            存在数据更新，则需要同步更新不同部署节点的本地缓存的数据来包保证数据一致性，复杂度较高并且容易出错，如基于 Redis 的发布订阅机制来同步更新各个部署节点。
        3. 数据随应用进程的重启而丢失
            由于本地缓存的数据是存储在应用进程的内存空间的，所以当应用进程重启时，本地缓存的数据会丢失。
            所以对于需要持久化的数据，需要注意及时保存，否则可能会造成数据丢失。

    适用场景：
        所以本地缓存一般适合于缓存只读数据，如统计类数据。或者每个部署节点独立的数据，如长连接服务中，每个部署节点由于都是维护了不同的连接，
        每个连接的数据都是独立的，并且随着连接的断开而删除。如果数据在集群的不同部署节点需要共享和保持一致，则需要使用分布式缓存来统一存储，
        实现应用集群的所有应用进程都在该统一的分布式缓存中进行数据存取即可。

    本地缓存的实现
    缓存一般是一种key-value的键值对数据结构，所以需要使用字典数据结构来实现，与此同时，本地缓存由于需要被不同的服务端线程并发读写，故需要保证线程安全。
        故一般会使用 ConcurrentHashMap 来作为 Java 编程中的本地缓存实现。除此之外，也有其他更加智能的本地缓存实现，如可以定时失效，访问重新加载等特性，
        典型实现包括 Google 的 guava 工具包的 Cache 实现，这些也是线程安全的。

    II、分布式缓存的优缺点
       1. 支持大数据量存储，不受应用进程重启影响
           分布式缓存由于是独立部署的进程，拥有自身独立的内存空间，不会受到应用进程重启的影响，在应用进程重启时，分布式缓存的数据依然存在。
           同时对于数据量而言，由于不需要占用应用进程的内存空间，并且一般支持以集群的方式拓展，故可以进行大数据量的数据缓存。
       2. 数据集中存储，保证数据一致性
           当应用进程采用集群方式部署时，集群的每个部署节点都通过一个统一的分布式缓存进行数据存取操作，故不存在本地缓存中的数据更新问题，保证了不同节点的应用进程的数据一致性问题。
       3. 数据读写分离，高性能，高可用
           分布式缓存一般支持数据副本机制，可以实现读写分离，故可以解决高并发场景中的数据读写性能问题。并且由于在多个缓存节点冗余存储数据，提高了缓存数据的可用性。
       3. 数据跨网络传输，性能低于本地缓存
           由于分布式缓存是独立部署的进程，并且一般都是与应用进程位于不同的机器，故需要通过网络来进行数据传输，这样相对于本地缓存的进程内部的数据读取操作，性能会较低。

    分布式缓存的实现
    分布式缓存的典型实现包括 MemCached 和 Redis。
    MemCached
        MemCached 相对于本地缓存的主要差别是以独立进程方式存在，数据集中存储，数据不随应用程序的重启而丢失。
        而 key-value 键值对的 value 也是一个简单的对象类型。
        所以 MemCached 进程相当于是在内存维护了一个非常大的哈希表来存储数据，对应的数据操作复杂度都是 O(1)，即常量级别，这也是 MemCached 高性能的一个实现方式，键值对存取速度都非常快。
    Redis
        Redis，更一步丰富了数据结构类型。并且 Redis 是单线程的，不存在并发数据读写的线程安全问题，以及更重要的是保证的数据读写操作的顺序性。
        除此之外，Redis 支持主从同步（读写分离）、集群分片拓展、数据持久化等特性，这也是 MemCached 不支持的。
        所以在高并发场景并且数据能够容忍极端情况下的少量丢失，或者说丢失后可以恢复，如通过日志或者重新计算等， Redis 也可以作为数据库来使用，提高高并发场景中的访问性能。

93.Redis分布式锁的实现原理？
    目前基于Redis实现的分布式锁常用的框架是Redisson,它的使用比较简单，在项目中引入Redisson的依赖，然后基于Redis实现分布式锁的加锁与释放锁。







    实现原理：
        1.客户端首先根据hash结点选择一台机器，紧接着就会发送一段lua脚本到redis上。
        2.lua脚本，把一大堆业务逻辑通过封装在lua脚本发送给redis，保证这段赋值业务逻辑执行的原子性。
        3.watch dog看门狗，是一个后台线程，会每隔10s检查一下，如果客户端A还持有锁key，那么就会不断延长锁key的生存时间。
        4.解锁时，执行lock.unlock()，每次对锁计数减一，如果锁计数为零了，就会使用“del MyLock”命令，从redis里删除key。
        5.客户端B尝试加锁，第一个if判断锁是否存在，第二个if判断锁id是否是自己，加锁失败就会进入自旋状态。
        6.缺点：
            异步数据丢失问题：客户端A对redis master实例写入锁，此时会异步复制给对应的master slave实例，这个过程中如果redis master宕机，
            主备切换，redis slave变成了新的redis master。这时候客户端B来尝试加锁，在新的redis master上完成了加锁，但是客户端A也自以为成功加锁。
            此时就会导致多个客户端对一个分布式锁完成了加锁，这时就会导致各种脏数据的产生。
        解决：
            红锁（Redlock）：客户端用相同的key和随机值在所有节点上请求锁，请求锁的超时时间应小于锁自动释放时间。
                超过半数N/2+1，才算是真正获取到了锁。这样就算其中某个redis节点挂掉，锁也不会被其他客户端获取到。
                如果没有获取到锁，则把部分已锁的redis释放掉。


94.限流算法？
    1、漏桶算法
        往漏斗里面倒水，不论倒多少水，下面出水的速率是恒定的。当漏斗满了，多余的水就被直接丢弃了。
        类比流量，每秒处理的速率是恒定的，如果有大量的流量过来就先放到漏斗里面。当漏斗也满了，请求则被丢弃
    2、令牌桶算法
        1）、所有的请求在处理之前都需要拿到一个可用的令牌才会被处理；
        2）、根据限流大小，设置按照一定的速率往桶里添加令牌；
        3）、桶设置最大的放置令牌限制，当桶满时、新添加的令牌就被丢弃或者拒绝；
        4）、请求达到后首先要获取令牌桶中的令牌，拿着令牌才可以进行其他的业务逻辑，处理完业务逻辑之后，将令牌直接删除；
        5）、因为桶中有存的令牌，所以令牌桶算法支持突发流量。

    对比：
        漏桶算法：请求都按固定的速度取走处理，常用于网络的流量整流。
        令牌桶算法：token放入速度是确定的，如果桶中存有token支持突发流量。
    实现：用ScheduledThreadPoolExecutor来定时从队列中取请求来执行/定时放令牌

95.spring IOC的底层实现
    反射，工厂。
    1、先通过creatBeanFactory创建出一个Bean工厂（DefaultListableBeanFactory）
    2、开始循环创建对象，容器中bean默认都是单例的，所以优先通过getBean、doGetBean从容器中查找
    3、若查不到，通过creatBean，doCreatBean的方法，以反射的方式创建对象，一般情况使用无参构造方法（getDeclaredConstructor.newInstance）
    4、进行对象的属性填充populateBean
    5、进行其他的初始化操作（initializingBean）

96.Spring事务底层如何实现？
    通过aop生成代理对象，通过代理对象生成事务拦截链TransactionInterceptor，调用invoke实现具体逻辑。

    1.根据事务传播等级等属性来判断是否开启事务。
    2.获取数据库连接，关闭自动提交，开启事务。
    3.执行具体的sql
    4.如果执行失败，通过completeTransationAfterThrowing来完成事务回滚，具体逻辑是通过doRollBack实现，先获取连接对象，通过连接对象回滚
    5.如果执行正常，通过commitTransactionAfterReturning来完成事务提交，具体逻辑是通过doCommit实现，先获取连接对象，通过连接对象提交


97.一次请求涉及的网络协议
    一、发请求：
        网址----------（IP）-----------DNS
        ↓
        请求---------------------------HTTP/HTTPS------------------------------------进程(tomcat)--------RPC---------专门的进程
        ↓                                                                            ↑
        传输---------------------------TCP-------------------------------------------传输层（tcp会确认回复，不行就ARQ）
        ↓                                                                            ↑
        网络---------------------------IP--------------------------------------------网络层
        ↓                                                                            ↑
        网关（默认192.108.1.1）-------------------ARP协议获取MAC----------------------目标服务器
    二、传输                                                                          ↑
        网关----------------------路由器，路由协议（RIP/OSPF/BGP）---------------------目标网关（会在局域网广播）

98.CSRF攻击？
    原理：攻击者引诱用户访问第三方页面B，这个页面B有请求被攻击网站A的URL，利用浏览器默认携带网站A的cookie，进而发起跨站请求。
    防御: 要抵御 CSRF，关键在于在请求中放入黑客所不能伪造的信息。
        因为伪造网站无法读取cookie，所以用户请求参数中带上cookie的值作为CSRF_token。
        1. 服务端生成一个随机的，不可预测的Token，放在用户的Session中，浏览器的Cookie中。
        2. 用户在页面表单附带上Token参数。
        3. 用户提交请求后， 服务端验证表单中的Token是否与用户Session中的Token一致，一致为合法请求，不是则非法请求。



99.HTTPS的混合加密？会有什么问题？
    1某网站拥有用于非对称加密的公钥A、私钥A’。
    2浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。
    3浏览器随机生成一个用于对称加密的密钥X，用公钥A加密后传给服务器。
    4服务器拿到后用私钥A’解密得到密钥X。
    5这样双方就都拥有密钥X了，且别人无法知道它。之后双方所有数据都通过密钥X加密解密即可。

    中间人攻击：
        如果在数据传输过程中，中间人劫持到了数据，此时他的确无法得到浏览器生成的密钥X，这个密钥本身被公钥A加密了，
        只有服务器才有私钥A’解开它，然而中间人却完全不需要拿到私钥A’就能干坏事了。请看：
            1某网站有用于非对称加密的公钥A、私钥A’。
            2浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。
            3中间人劫持到公钥A，保存下来，把数据包中的公钥A替换成自己伪造的公钥B（它当然也拥有公钥B对应的私钥B’）。
            4浏览器生成一个用于对称加密的密钥X，用公钥B（浏览器无法得知公钥被替换了）加密后传给服务器。
            5中间人劫持后用私钥B’解密得到密钥X，再用公钥A加密后传给服务器。
            6服务器拿到后用私钥A’解密得到密钥X。
        这样在双方都不会发现异常的情况下，中间人掉包了服务器传来的公钥，进而得到了密钥X。
        根本原因是浏览器无法确认收到的公钥是不是网站自己的，因为公钥本身是明文传输的，解决办法是CA数字证书。

100.CA怎么解决中间人攻击问题？
    网站在使用HTTPS前，需要向CA机构申领一份数字证书，数字证书里含有证书持有者信息、公钥信息等。
    服务器把证书传输给浏览器，浏览器从证书里获取公钥就行了，证书就如身份证，证明“该公钥对应该网站”。
    而这里又有一个显而易见的问题，“证书本身的传输过程中，如何防止被篡改”？数字证书怎么防伪呢？解决这个问题我们就接近胜利了！

    我们把证书原本的内容散列生成一份“数字签名”，比对证书内容和签名是否一致就能判别是否被篡改。这就是数字证书的“防伪技术”。

