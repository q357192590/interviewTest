一、HashMap线程安全性问题
    1 多线程的put可能导致元素的丢失
        同时put的覆盖。
    2 put和get并发时，可能导致get为null
        线程1执行put时，因为元素个数超出threshold而导致rehash，线程2此时执行get，有可能导致这个问题。
    3 JDK7中HashMap并发put会造成循环链表，导致get时出现死循环
        发生在多线程并发resize的情况下。
二、HashMap 与 ConcurrentHashMap 的实现原理是怎样的？ConcurrentHashMap 是如何保证线程安全的？
    1 数组链表(1.7)红黑树(1.8) / 数组链表(1.7)红黑树(1.8)
    2 不建议并发 / Segment(1.7)Node(1.8)

        首先new一个新的hash表(nextTable)出来，大小是原来的2倍。后面的rehash都是针对这个新的hash表操作，不涉及原hash表(table)。
        然后会对原hash表(table)中的每个链表进行rehash，此时会尝试获取头节点的锁。这一步就保证了在rehash的过程中不能对这个链表执行put操作。
        3 通过sizeCtl控制，使扩容过程中不会new出多个新hash表来。
        2 最后，将所有键值对重新rehash到新表(nextTable)中后，用nextTable将table替换。这就避免了HashMap中get和扩容并发时，可能get到null的问题。
        在整个过程中，共享变量的存储和读取全部通过volatile或CAS的方式，保证了线程安全。
        1 put的时候加锁。
三、volatile 关键字解决了什么问题，它的实现原理是什么？
    可见性、有序性。

    volatile可见性的实现就是借助了CPU的lock指令，通过在写volatile的机器指令前加上lock前缀，使写volatile具有以下两个原则：
    写volatile时处理器会将缓存写回到主内存。
    一个处理器的缓存写回到内存会导致其他处理器的缓存失效。

    禁止指令重排序又是如何实现的呢？答案是加内存屏障。JMM为volatile加内存屏障有以下4种情况：
    在每个volatile写操作的前面插入一个StoreStore屏障，防止写volatile与后面的写操作重排序。
    在每个volatile写操作的后面插入一个StoreLoad屏障，防止写volatile与后面的读操作重排序。
    在每个volatile读操作的后面插入一个LoadLoad屏障，防止读volatile与后面的读操作重排序。
    在每个volatile读操作的后面插入一个LoadStore屏障，防止读volatile与后面的写操作重排序。

四、Synchronized 关键字底层是如何实现的？它与 Lock 相比优缺点分别是什么？

    synchronized同步代码块的时候通过加入字节码monitorenter和monitorexit指令来实现monitor的获取和释放， 也就是需要JVM通过字节码显式的去获取和释放monitor实现同步，
    而synchronized同步方法的时候，没有使用这两个指令， 而是检查方法的ACC_SYNCHRONIZED标志是否被设置，如果设置了则线程需要先去获取monitor，执行完毕了线程再释放monitor，也就是不需要JVM去显式的实现。
    这两个同步方式实际都是通过获取monitor和释放monitor来实现同步的，而monitor的实现依赖于底层操作系统的mutex互斥原语， 而操作系统实现线程之间的切换的时候需要从用户态转到内核态，这个转成过程开销比较大。

    1、原始构成
        JVM层面/api层面
    2、使用方法
        手动释放锁/自动释放
    3、等待是否可中断
        不可中断/可中断
            中断方法：设置超时方法tryLock()、代码块中放lockInterruptibly()，调用interrupt()。
    4、加锁是否公平
        非公平/非公平，可实现公平
    5、绑定多个条件Condition
        达咩/可用Condition精确唤醒

五、Java 中垃圾回收机制中如何判断对象需要回收？常见的 GC 回收算法有哪些？
    引用计数算法：可能有循环引用的方法，故放弃
    可达性分析算法：
        可作为 GC Root 的对象包括以下4种：
        1虚拟机栈（栈帧中的本地变量表）中引用的对象
        2方法区中类静态属性引用的对象
        3方法区中常量引用的对象
        4本地方法栈中 JNI（即一般说的 Native 方法）引用的对象

    标记 --- 清除算法
    复制算法
    标记整理算法
    分代收集算法：在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。
                 而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用标记-清理或者标记 --- 整理算法来进行回收

六、ThreadLocal key为什么设计成弱引用？
    对于一个 ThreadLocal 对象，通常会有两个引用指向它：
        一个是线程中声明的 threadLocal 变量，这是个强引用；
        一个是线程底层 ThreadLocalMap 中键值对的 key，这是弱引用。
    不再需要使用某 ThreadLocal 对象时，会采用将变量设置为 null（threadLocal = null）的方式释放掉线程中 threadLocal 变量与对象之间的引用关系，方便 GC 对 ThreadLocal 对象的回收。
    但此时线程的 ThreadLocalMap 中还有 key 引用着这个 ThreadLocal 对象：如果这个引用是强引用，那么这个 ThreadLocal 对象就可能永远不会被回收了，造成内存泄露；
    但现在这里设计成弱引用，那么当垃圾收集器发现这个 ThreadLocal 对象只有弱引用相关联时，就会回收它的内存。

七、String 类能不能被继承？为什么？
    主要是为了 “ 效率 ” 和 “ 安全性 ” 的缘故。 若 String 允许被继承, 由于它的高度被使用率, 可能会降低程序的性能，所以 String 被定义成 final。

    因为字符串是不可变的，所以是多线程安全的。
    类加载器要用到字符串，不可变性提供了安全性。
    只有当字符串是不可变的，字符串池才有可能实现。
    因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键。

八、JMM 中内存模型是怎样的？什么是指令序列重排序？
    堆、方法区。本地方法栈、虚拟机栈、程序计数器。

    指令序列的重排序：
    1）编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
    2）指令级并行的重排序。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
    3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

九、Java 线程和操作系统的线程是怎么对应的？Java线程是怎样进行调度的?（？？）
    Linux 2.6上的HotSpot使用了NPTL机制，JVM线程跟内核轻量级进程有一一相应的关系
    Java线程在Windows及Linux平台上的实现方式是内核线程的实现方式。
    这样的方式实现的线程，是直接由操作系统内核支持的——由内核完毕线程切换，内核通过操纵调度器（Thread Scheduler）实现线程调度，并将线程任务反映到各个处理器上。
    内核线程是内核的一个分身。程序一般不直接使用该内核线程，而是使用其高级接口，即轻量级进程（LWP）。也即线程。

十、简述 BIO, NIO, AIO 的区别？
    bio :同步阻塞，服务器实现模式是一个连接一个线程，当客户端发来连接时服务器就需要启动一个线程进行处理，
        如果这个连接不做任何事情就会造成不必要的线程开销，当然线程池机制可以改善。

    nio:同步非阻塞，服务器实现模式为多个请求一个线程，即客户端发来的请求都会注册到多路复用器上，
        多路复用器轮训的连接有io请求时才开启一个线程进行处理。

    aio:异步非阻塞，服务器实现模式为多个有效请求一个线程。
        即客户端发来的请求由os处理完成才会通知服务器应用启动线程进行处理。

十一、请你谈谈对OOM的认识
    1 java.lang.StackOverflowError
    栈空间溢出，递归调用卡死

    2 java.lang.OutOfMemoryError:Java heap space
    堆内存溢出，对象过大

    3 java.lang.OutOfMemoryError:GC overhead limit exceeded
    GC回收时间过长：超过98%的时间用来做GC并且回收了而不倒2%的堆内存。连续多次GC，cpu使用率一直是100%，而GC却没有任何成果。

    4 java.lang.OutOfMemoryError:Direct buffer memory
    本地内存挂了
    写NIO程序经常使用ByteBuffer来读取或写入数据，这是一种基于通道（Channel）与缓存区（Buffer)的I/O方式，它可以使用Native函数库直接分配堆外内存，
    然后通过一个存储在java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作，这样能在一些场景中显著提高性能，因为避免了在java堆和native堆中来回复制数据
        ByteBuffer.allocate(capability) 第一种方式是分配JVM堆内存，属于GC管辖，由于需要拷贝所以速度较慢
        ByteBuffer.alloctedDirect(capability)分配os本地内存，不属于GC管辖，不需要拷贝，速度较快
    但如果不断分配本地内存，堆内存很少使用，那么jvm就不需要执行GC，DirectByteBuffer对象们就不会被回收，这时候堆内存充足，但本地内存可能已经使用光了，再次尝试分配本地内存就会出现oom，程序崩溃

    5 java.lang.OutOfMemoryError:unable to create new native thread
    应用创建了太多线程，一个应用进程创建了多个线程，超过系统承载极限
    你的服务器并不允许你的应用程序创建这么多线程，linux系统默认允许单个进程可以创建的线程数是1024，超过这个数量，就会报错

    解决办法：
    降低应用程序创建线程的数量，分析应用给是否针对需要这么多线程，如果不是，减到最低
    修改linux服务器配置，扩大默认限制。

    6 java.lang.OutOfMemoryError:Metaspace
    元空间主要存放了虚拟机加载的类的信息、常量池、静态变量、即时编译后的代码

十二、GC垃圾回收算法和垃圾收集器的关系？分别是什么？※
    垃圾收集器就是算法的具体实现

    GC算法：引用计数、复制、标记清理、标记整理

    4种主要垃圾收集器
    Serial串行回收：为单线程换进该设计且只是用过一个线程进行垃圾回收，会暂停所有的用户线程，不适合服务器环境

    Paralle并行回收：多个垃圾收集线程并行工作，此时用户线程是暂停的，适用于科学计算/大数据处理首台处理等弱交互场景

    CMS并发标记清除：用户线程和垃圾收集线程同时执行（不一定是并行，可能交替执行），不需要停顿用户线程，互联网公司多用它，适用堆响应时间有要求的场景

    G1：将堆内存分割城不同的区域然后并发的对其进行垃圾回收

十三、怎么查看服务器默认的垃圾收集器是哪个？生产上如何配置垃圾收集器？对垃圾收集器的理解？
   查看：java -XX:+PrintCommandLinedFlags -version（查看jvm默认的命令行参数）
   配置：有六种：UseSerialGC UseParallelGC UseConcMarkSweepGC UseParNewGC UseParallelOldGC UseG1GC

   收集器：
   新生代：serial收集器（串行GC）、 parNew（新生代并行老年代串行） 、 Parallel（并行GC）
   老年代：CMS 、 Serial Old 、 Parallel Old

   | 参数                              | 新生代垃圾收集器     | 新生代算法         | 老年代垃圾收集器                                              | 老年代算法 |
   | --------------------------------- | ------------------ | ------------------ | ------------------------------------------------------------ | ----------|
   | UseSerialGC                       | SerialGC           | 复制               | SerialOldGC                                                  | 标整       |
   | UseParNewGC                       | ParNew             | 复制               | SerialOldGC                                                  | 标整       |
   | UseParallelGC<br>UseParallelOldGC | Parallel[Scavenge] | 复制               | Parallel Old                                                 | 标整       |
   | UseConcMarkSweepGC                | ParNew             | 复制               | CMS+Serial Old的收集器组合(Serial Old 作为CMS出错的后备收集器) | 标清       |
   | UseG1GC                           | G1整体上采用标整    | 局部是通过复制算法  |                                                              |            |

十四、如何选择垃圾选择器？

    - 单CPU或小内存，单机内存
      -XX:+UseSerialGC

    - 多CPU，需要最大吞吐量，如后台计算型应用
      -XX:+UseParallelGC    -XX:+UseParallelOldGC

    - 多CPU，最求低停顿时间，需快速相应，如互联网应用
      -XX:+ParNewGC    -XX:+UseConcMarkSweepGC

十五、G1和CMS相比优势
    1. G1不会产生内存碎片
    2. 可以精确控制停顿。该收集器是把整个堆划分成多个固定大小的区域，每根据允许停顿的时间去收集垃圾最多的区域

十六、生产环境服务器变慢，诊断思路和性能评估谈谈？
    1. 整机：top 系统性能
        uptime 是它的精简版
        load average：系统负载均衡 1min 5min 15min 系统的平均负载值 相加/3>60%压力够
    2. CPU：vmstat
        - 查看CPU
            vmstat -n 2 3 第一个参数是采样的时间间隔数单位s，第二个参数是采样的次数

        - procs
            **r**：运行和等待CPU时间片的进程数，原则上1核CPu的运行队列不要超过2，真个系统的运行队列不能超过总核数的2倍，否则表示系统压力过大
            **b**：等待资源的进程数，比如正在等待磁盘I/O，网络I/O等
        - cpu
            **us**：用户进程消耗cpu时间百分比，us高，用户进程消耗cpu时间多，如果长期大于50%，优化程序
            **sy**：内核进程消耗的cpu时间百分比
            **us+sy**：参考值为80%，如果大于80，说明可能存在cpu不足
        - 查看额外
            - 查看所有cpu核信息   mpstat -P ALL 2
            - 每个进程使用cpu的用量分解信息   pidstat -u 1 -p 进程编号
    3. 内存：free
        查看内存   free -m   free -g
        pidstat -p 进程编号 -r 采样间隔秒数
    4. 硬盘：df
        查看磁盘剩余空间  df -h
    5. 磁盘IO：iostat
        - 磁盘I/O性能评估
            iostat -hdk 2 3
            - util 一秒中又百分几的时间用于I/O操作，接近100%时，表示磁盘带宽跑满，需要优化程序或加磁盘

        - pidstat -d 采样间隔秒数 -p 进程号
    6. 网络IO：ifstat
       ifstat l

十七、假如生产环境CPU占用过高，谈谈分析思路和定位？
    1. 先用top命令找出cpu占比最高的pid
    2. ps -ef或者jps进一步定位，得知是一个怎样的后台程序惹事（可省）
       - jps -l
       - ps -ef|grep java|grep -v grep
    3. 定位到具体线程或者代码
       - ps -mp 进程编号 -o Thread,tid,time
         定位到具体线程
         -m ：显示所有的线程
         -p pid 进程使用cpu的时间
         -o：该参数后是用户自定义格式
    4. 将需要的线程ID转换为16禁止格式（英文小写格式）
       - printf "%x\n" 线程ID
    5. jstack 进程Id|grep tid(16进制线程id小写英文) -A60
       查看运行轨迹，堆栈异常信息

十八、LockSupport是什么？
    LockSupport是用来创建锁和其他同步类的基本线程阻塞原语。
    总之，比wait/notify，await/signal更强。
        1、无需要放在锁块中。
        2、LockSupport可无视park、unpark的先后顺序。

    3种让线程等待和唤醒的方法：
        方式1：使用Object中的wait()方法让线程等待，使用object中的notify()方法唤醒线程
        方式2：使用JUC包中Condition的await()方法让线程等待，使用signal()方法唤醒线程
        方式3：LockSupport类可以阻塞当前线程以及唤醒指定被阻塞的线程

十九、LockSupport为什么唤醒两次后阻塞两次，但最终结果还会阻塞线程？
    因为凭证permit的数量最多为1（不能累加），连续调用两次 unpark和调用一次 unpark效果一样，
    只会增加一个凭证；而调用两次park却需要消费两个凭证，证不够，不能放行。

二十、简述AQS
    AQS使用一个volatile的int类型的成员变量来表示同步状态，通过内置的FIFo队列来完成资源获取的排队工作
    将每条要去抢占资源的线程封装成一个Node，节点来实现锁的分配，通过CAS完成对State值的修改。

二十一、AOP执行顺序：
    springboot1：
        正常情况下：@Before前置通知----->@After后置通知----->@AfterRunning正常返回
        异常情况下：@Before前置通知----->@After后置通知----->@AfterThrowing方法异常
    springboot2：
        正常：我是环绕通知之前AAA
            ********@Before我是前置通知
            ===>CalcServiceImpl被调用，计算结果为：5
            ********@AfterReturning我是返回后通知
            ********@After我是后置通知
            我是环绕通知之后BBB
        异常：我是环绕通知之前AAA
            ********@Before我是前置通知
            ********@AfterThrowing我是异常通知
            ********@After我是后置通知
            java.lang.ArithmeticException: / by zero

二十二、什么是循环依赖？如何解决？
    多个bean之间相互依赖，形成了一个闭环。比如：A依赖于B、B依赖于C、C依赖于A。会报BeanCurrentlyInCreationException

    AB循环依赖问题只要A的注入方式是set注入或bean本身是singleton ，就不会有循环依赖问题。(构造注入因为实例还没构造，无法提前曝光)
    spring内部通过三级缓存来解决循环依赖问题。

二十三、spring内部如何通过三级缓存来解决循环依赖问题？
    DefaultSingletonBeanRegistry
    只有单例的bean会通过三级缓存提前暴露来解决循环依赖的问题，而非单例的bean，每次从容器中获取都是一个新的对象，都会重新创建，所以非单例的bean是没有缓存的，不会将其放到三级缓存中。

    第一级缓存（也叫单例池）singletonObjects：存放已经经历了完整生命周期的Bean对象。（成品）
    第二级缓存：earlySingletonObjects，存放早期暴露出来的Bean对象，Bean的生命周期未结束（属性还未填充完。 （半成品）
    第三级缓存：Map<String, ObjectFactory<?>> singletonFactories，存放可以生成Bean的工厂。   （准备生产）

    A / B两对象在三级缓存中的迁移说明：
        A创建过程中需要B，于是A将自己放到三级缓里面，去实例化B。
        B实例化的时候发现需要A，于是B先查一级缓存，没有，再查二级缓存，还是没有，再查三级缓存，找到了A然后把三级缓存里面的这个A放到二级缓存里面，并删除三级缓存里面的A。
        B顺利初始化完毕，将自己放到一级缓存里面（此时B里面的A依然是创建中状态)，然后回来接着创建A，此时B已经创建结束，直接从一级缓存里面拿到B，然后完成创建，并将A自己放到一级缓存里面。
    主要方法：
        getSingleton()、doCreatBean()、populateBean()、addSingleton()

二十四、Redis基本类型及使用场景？
    String：
        商品编号、订单号采用INCR命令生成
        点赞
    Hash：
        购物车早期，当前小中厂可用
    List:
        微信文章订阅公众号,粉丝列表
    Set：
        微信抽奖小程序、微信朋友圈点赞、共同关注的人、猜你喜欢
    ZSet：
        根据商品销售量排序显示

二十五、分布式锁
    多个服务间 + 保证同一时刻内 + 同一用户只能有一个请求（防止关键业务出现数据冲突和并发错误）

    卖票程序：1->2加锁synchronized
            2->3加分布式锁 RedisTemplate
            3->4必须finally释放锁
            4->5防止机器宕机，需要给redis的key设置过期时间
            5->6加锁和设置expire必须要是原子操作
            6->7线程可能会误删他人锁，一定要判断是自己的锁
            7->8判断自己锁和删除锁不是原子操作。解锁过程可用lua脚本、Redis事务、Redisson
            8->9风险：Redis过期时间大于业务执行、Redis分布式锁如何续期？
                    Redis - AP -redis异步复制造成的锁丢失，比如：主节点没来的及把刚刚set进来这条数据给从节点，就挂了。
                    (ZooKeeper - CP)
                    (CAP
                        C：Consistency（强一致性）
                        A：Availability（可用性）
                        P：Partition tolerance（分区容错性）)
                    解决：Redis集群环境下，我们自己写的也不OK，直接上RedLock之Redisson落地实现。
            9->10健壮：解锁前判断是否加锁，并且锁是自己持有的

二十六、Redis内存满了怎么办？Redis默认内存多少？在哪里查看？如何设置修改？
    查看Redis最大占用内存
        配置文件redis.conf的maxmemory参数，maxmemory是bytes字节类型，注意转换。
    redis默认内存多少可以用？
        如果不设置最大内存大小或者设置最大内存大小为0，在64位操作系统下不限制内存大小，在32位操作系统下最多使用3GB内存
    一般生产上你如何配置？
        一般推荐Redis设置内存为最大物理内存的四分之三。
    如何修改redis内存设置
        1修改配置文件redis.conf的maxmemory参数，如：maxmemory 104857600（100MB）
        2通过命令修改
            config set maxmemory 1024
            config get maxmemory
    什么命令查看redis内存使用情况?
        info memory

二十七、如果Redis内存使用超出了设置的最大值会怎样?
    (error) OOM command not allowed when used memory > 'maxmemory'.

二十八、Redis内存淘汰策略，如何配置，修改？
    noeviction：不会驱逐任何key（不要用）
    volatile-lfu：对所有设置了过期时间的key使用LFU算法进行删除
    volatile-lru：对所有设置了过期时间的key使用LRU算法进行删除
    volatile-random：对所有设置了过期时间的key随机删除
    volatile-ttl：删除马上要过期的key
    allkeys-lfu：对所有key使用LFU算法进行删除
    allkeys-lru：对所有key使用LRU算法进行删除（最常用）
    allkeys-random：对所有key随机删除（不要用）

    命令：
        config set maxmemory-policy noeviction
        config get maxmemory-policy
    配置文件 - 配置文件redis.conf的maxmemory-policy参数

二十九、过滤器和拦截器的区别？
    过滤器：
        是在java web中，你传入的request,response提前过滤掉一些信息，然后再传入servlet进行业务逻辑，
        比如过滤掉非法url（不是login.do的地址请求，如果用户没有登陆都过滤掉）,或者在传入servlet前统一设置字符集，或者去除掉一些非法字符
    拦截器：
        是在面向切面编程的就是在你的service或者一个方法，前调用一个方法，或者在方法后调用一个方法比如动态代理就是拦截器的简单实现，

    拦截器与过滤器的区别 ：
        1.拦截器是基于java的反射机制的，而过滤器是基于函数回调。
        2.拦截器不依赖与servlet容器，过滤器依赖与servlet容器。
        3.拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。
        4.拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。
        5.在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次

三十、OSI ， TCP/IP ，五层协议的体系结构？
    物理层：激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性。
        该层为上层协议提供了一个传输数据的物理媒体。

    数据链路层 ：数据链路层在不可靠的物理介质上提供可靠的传输。
        该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。

    网络层 ：网络层负责对子网间的数据包进行路由选择。
        此外，网络层还可以实现拥塞控制、网际互连等功能。

    传输层 ：第一个端到端，即主机到主机的层次。传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输。
        此外，传输层还要处理端到端的差错控制和流量控制问题。

    会话层 ：会话层管理主机之间的会话进程，即负责建立、管理、终止进程之间的会话。
        会话层还利用在数据中插入校验点来实现数据的同步。

    表示层 ：表示层对上层数据或信息进行变换以保证一个主机应用层信息可以被另一个主机的应用程序理解。
        表示层的数据转换包括数据的加密、压缩、格式转换等。

    应用层 ：为操作系统或网络应用程序提供访问网络服务的接口。

三十一、ARP 协议的工作原理
    首先，每台主机都会在自己的ARP缓冲区中建立一个 ARP列表，以表示IP地址和MAC地址的对应关系。
    当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP列表中是否存在该 IP地址对应的MAC地址，
    如果有，就直接将数据包发送到这个MAC地址；如果没有，就向本地网段发起一个ARP请求的广播包，查询此目的主机对应的MAC地址。
    此ARP请求数据包里包括源主机的IP地址、硬件地址、以及目的主机的IP地址。
    网络中所有的主机收到这个ARP请求后，会检查数据包中的目的IP是否和自己的IP地址一致。
    如果不相同就忽略此数据包；如果相同，该主机首先将发送端的MAC地址和IP地址添加到自己的ARP列表中，如果ARP表中已经存在该IP的信息，则将其覆盖，
    然后给源主机发送一个 ARP响应数据包，告诉对方自己是它需要查找的MAC地址；
    源主机收到这个ARP响应数据包后，将得到的目的主机的IP地址和MAC地址添加到自己的ARP列表中，并利用此信息开始数据的传输。
    如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。

三十二、常见的路由选择协议，以及它们的区别？
    常见的路由选择协议有：RIP协议、OSPF协议。
    RIP协议 ：内部网关协议，底层是贝尔曼福特算法，它选择路由的度量标准（metric)是跳数，最大跳数是15跳，如果大于15跳，它就会丢弃数据包。
    OSPF协议 ：内部网关协议，底层是迪杰斯特拉算法，是链路状态路由选择协议，它选择路由的度量标准是带宽，延迟。
    BGP协议：外部网关协议。

三十三、在浏览器中输入 www.baidu.com 后执行的全部过程？

    现在假设如果我们在客户端（客户端）浏览器中输入http://www.baidu.com,而baidu.com为要访问的服务器（服务器），下面详细分析客户端为了访问服务器而执行的一系列关于协议的操作：

    1）客户端浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径。
        客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层。

    2）在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，
        如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。

    3）客户端的网络层不用关系应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，
        这些都是由路由器来完成的工作，我不作过多的描述，无非就是通过查找路由表决定通过那个路径到达服务器。

    4）客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，
        然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。

三十四、HTTP 中， POST 与 GET 的区别

    (1)Get是从服务器上获取数据，Post是向服务器传送数据。
    (2)Get是把参数数据队列加到提交表单的Action属性所指向的URL中，值和表单内各个字段一一对应，在URL中科院看到。
    (3)Get传送的数据量小，不能大于2KB；post传送的数据量较大，一般被默认为不受限制。
    (4)根据HTTP规范，GET用于信息获取，而且应该是安全的和幂等的。
        I.所谓 安全的 意味着该操作用于获取信息而非修改信息。换句话说，GET 请求一般不应产生副作用。就是说，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态。
        II. 幂等 的意味着对同一URL的多个请求应该返回同样的结果。

三十五、TCP/IP 中，每一层对应的协议

    网络层 ：IP协议、ICMP协议、ARP协议、RARP协议。

    传输层 ：UDP协议、TCP协议。

    应用层 ：FTP（文件传送协议）、Telenet（远程登录协议）、DNS（域名解析协议）、SMTP（邮件传送协议），
            POP3协议（邮局协议），HTTP协议。

三十六、TCP 对应的协议和 UDP 对应的协议

    TCP对应的协议：

    （1） FTP ：定义了文件传输协议，使用21端口。常说某某计算机开了FTP服务便是启动了文件传输服务。下载文件，上传主页，都要用到FTP服务。

    （2） Telnet ：它是一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，通过这种端口可以提供一种基于DOS模式下的通信服务。
        如以前的BBS是-纯字符界面的，支持BBS的服务器将23端口打开，对外提供服务。

    （3） SMTP ：定义了简单邮件传送协议，现在很多邮件服务器都用的是这个协议，用于发送邮件。
        如常见的免费邮件服务中用的就是这个邮件服务端口，所以在电子邮件设置-中常看到有这么SMTP端口设置这个栏，服务器开放的是25号端口。

    （4） POP3 ：它是和SMTP对应，POP3用于接收邮件。通常情况下，POP3协议所用的是110端口。
        也是说，只要你有相应的使用POP3协议的程序（例如Fo-xmail或Outlook），就可以不以Web方式登陆进邮箱界面，直接用邮件程序就可以收到邮件（如是163邮箱就没有必要先进入网易网站，再进入自己的邮-箱来收信）。

    （5）HTTP协议： 是从 Web 服务器传输超文本到本地浏览器的传送协议。

    UDP对应的协议：

    （1） DNS ：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。

    （2） SNMP ：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。

    （3） TFTP (Trival File Transfer Protocal)，简单文件传输协议，该协议在熟知端口69上使用UDP服务。

三十七、NAT 协议、 DHCP 协议、 DNS 协议的作用？
    NAT协议 ：网络地址转换(NAT,Network AddressTranslation)属接入广域网(WAN)技术，
        是一种将私有（保留）地址转化为合法IP地址的转换技术，它被广泛应用于各种类型Internet接入方式和各种类型的网络中。
        原因很简单，NAT不仅完美地解决了lP地址不足的问题，而且还能够有效地避免来自网络外部的攻击，隐藏并保护网络内部的计算机。

    DHCP协议 ：动态主机设置协议（Dynamic Host ConfigurationProtocol, DHCP）
        是一个局域网的网络协议，使用UDP协议工作，主要有两个用途：给内部网络或网络服务供应商自动分配IP地址，给用户或者内部网络管理员作为对所有计算机作中央管理的手段。

    DNS协议 ：DNS 是域名系统 (Domain Name System) 的缩写，是因特网的一项核心服务，
        它作为可以将域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。

三十八、happen-before 原则
    程序顺序规则：一个线程内执行的每个操作，都保证 happen-before 后面的操作，这样就保证了程序顺序规则，
    volatile 变量规则：对于 volatile 变量，对他的写操作，保证 happen-before 在随后对改变量的读取操作。
    监视器锁规则：对于一个锁的解锁操作，保证 happen-before 加锁操作。
    线程启动 happen-before 规则：Thread 对象的 start() 方法先行于此线程的每一个动作
    线程中断 happen-before 规则：对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生。
    线程终结规则：假定线程A在执行的过程中，通过制定ThreadB.join()等待线程B终止，那么线程B在终止之前对共享变量的修改在线程A等待返回后可见。
    对象终结规则，一个对象的初始化完成happen-before 于 finalizer() 方法的开始
    传递性：happen-before 存在传递性，a happen-before b ,b happen-before c ,那么 a happen-before c 。
    happen-before 保障了顺序执行，也包括了内存读写的操作顺序。

三十九、HTTP的常见状态码有哪些，代表什么含义？
    常见状态码：
    200 OK：正常返回信息
    400 Bad Request：客户端请求有语法错误，不能被服务器所理解
    403 Forbidden：服务器收到请求，但是拒绝提供服务
    404 Not Found：请求资源不存在，输入了错误的URL
    500 Internal Server Error：服务器发生不可预期错误
    503 Server Unavailable：服务器当前不能处理客户端的请求，一段时间后可能恢复正常

四十、什么是加密？什么是数字签名？什么是数字证书？区别？
    加密：用加密算法将加密对象处理，用公钥加密，私钥解密。保证数据不被别人看到。
    数字签名：用私钥加密，公钥解密。保证数据是我自己发的，有任何篡改都能被识别、
    数字证书：对称加密中，双方使用公钥进行解密。虽然数字签名可以保证数据不被替换，
        但是数据是由公钥加密的，如果公钥也被替换，则仍然可以伪造数据，因为用户不知道对方提供的公钥其实是假的。
        所以为了保证发送方的公钥是真的，CA 证书机构会负责颁发一个证书，里面的公钥保证是真的，
        用户请求服务器时，服务器将证书发给用户，这个证书是经由系统内置证书的备案的。
        
四十一、springboot中bean的生命周期？
    Bean 容器找到配置文件中 Spring Bean 的定义。（@Component等）
    Bean 容器利用 Java Reflection API 创建一个Bean的实例。（无参、有参构造方法（实例化））
    如果涉及到一些属性值 利用 set() 方法设置一些属性值。（依赖注入）
        如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName() 方法，传入Bean的名字。 如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader() 方法， 传入 ClassLoader 对象的实例。
        与上面的类似，如果实现了其他 *.Aware 接口，就调用相应的方法。
    如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执 行postProcessBeforeInitialization() 方法（初始化前置方法）
    如果Bean实现了 InitializingBean 接口，执行 afterPropertiesSet() 方法。（初始化-自定义逻辑）
    如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。（初始化-自定义逻辑）
    如果有和加载这个 Bean的 Spring 容器相关的 BeanPostProcessor 对象，执 行postProcessAfterInitialization() 方法（初始化后置方法）
    当要销毁 Bean 的时候，如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。
    当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定 的方法。
    
四十二、spring中Aware接口和BeanPostProcessor和BeanFactoryPostProcessor的区别？
    （1）从调用时间点上看，Aware接口的方法（都是setXXX方法）是在Bean的属性被设置之后，
            初始化方法初始化方法（InitializingBean接口的方法，或@PostContruct等）执行之前被调用（这个时候Bean的整个初始化过程还没有完成）
        BeanPostProcessor接口由两个回调方法组成，初始化方法（InitializingBean接口的方法，或@PostContruct等）执行之前调用BeanPostProcessor的postProcessBeforeInitialization回调，
            并在初始化方法执行之后调用BeanPostProcessor的postProcessAfterInitialization回调；
        BeanFactoryPostProcessor是在容器初始化之前被调用。
    （2）从功能上来看，BeanPostProcessor主要是用来对实例化后的Bean做操作；
        BeanFactoryPostProcessor可以取得BeanFactory的引用，对实例化前的Bean定义做操作。
        Aware接口分的比较细，可以取得各种引用，例如：ApplicationContext，BeanFactory，MessageSource等等。
            在ApplicationContextAware接口里，也可以可以通过ApplicationContext取得BeanFactory，但要注意Aware接口方法的被调用时间点和BeanFactoryPostProcessor不一样。（也可以使用BeanFactoryAware接口取得BeanFactory）
    （3）从实现上看，Aware接口的回调其实是通过BeanPostProcessor接口实现的。
            可以看一下ApplicationContextAwareProcessor这个类，这个类继承了BeanPostProcessor接口。
            这个类的处理逻辑就是，看Bean是否是几个Aware接口的实例，如果是的话就调用接口提供的回调。
            
四十二、InitializingBean的作用？和init-method有什么区别？
    InitializingBean 接口为 bean 提供了 初始化方法的方式，接口只包括一个无返回值的 afterPropertiesSet 方法，凡是继承该接口的类，在初始化 bean 的时候都会执行该方法
    
    1：spring为bean提供了两种初始化bean的方式，实现InitializingBean接口，实现afterPropertiesSet方法，或者在配置文件中通过init-method指定，两种方式可以同时使用
    2：实现InitializingBean接口是直接调用afterPropertiesSet方法，比通过反射调用init-method指定的方法效率相对来说要高点。但是init-method方式消除了对spring的依赖
    3：调用afterPropertiesSet方法在前。如果调用afterPropertiesSet方法时出错，则不调用init-method指定的方法。
        
四十三、Dubbo集群提供的负载均衡策略？介绍下一致性hash策略？
    Random LoadBalance: 随机选取提供者策略，有利于动态调整提供者权重。截面碰撞率高，调用次数越多，分布越均匀；（权重概率）
    RoundRobin LoadBalance: 轮循选取提供者策略，平均分布，但是存在请求累积的问题；（轮询）
    LeastActive LoadBalance: 最少活跃调用策略，解决慢提供者接收更少的请求；（找最快的）
    ConstantHash LoadBalance: 一致性Hash策略，使相同参数请求总是发到同一提供者，一台机器宕机，可以基于虚拟节点，分摊至其他提供者，避免引起提供者的剧烈变动；

    普通的hash算法： hash值 % 服务器数 -> 服务器数量变化 -> 缓存大面积失效 -> 缓存雪崩
    一致性hash算法： 根据后端节点的某个固定属性计算 hash 值，然后把所有节点计算出来的 hash 值放在一个2的32次方节点数的 hash 圆环。
                请求过来的时候根据请求的特征计算 hash 值，然后顺时针查找 hash 环上的 hash 值，第一个比请求特征的 hash 值大的 hash 值所对应的节点即为被选中的节点。
                当服务器数量发生变化，可以使得只有少部分缓存失效
                缺点：hash偏斜 -> 部分节点上承受太多的请求 -> 引入虚拟节点 -> 每个实际节点重复 n 次，放入hash圆环上

四十四、缓存雪崩、穿透、击穿
    雪崩：同一时间缓存大面积失效。
        1、redis存数据的时候加随机过期时间expire
        2、设置热点数据永不过期，有更新操作更新缓存（电商首页）
    穿透：用户不断发起请求，缓存和数据库都没有的数据。（id为负数或者很大值的用户）
        1、在接口层增加参数校验，不合法参数直接返回。
        2、将不存在的key对应的value写为null、稍后重试等，并将过期时间设置短点
        3、网关层nginx有配置项，可以对单ip每秒访问次数超过阈值的ip拉黑
        4、布隆过滤器：利用搞笑的数据结构和算法快速判断是不是在数据库中存在。（布谷鸟过滤器）
    击穿：某个key非常热点，扛着大并发，突然这个key失效，直接请求数据库
        1、设置热点数据永不过期

四十五、解释分库分表？
    垂直分库：（免费表、会员可用表）
        按表的业务归属不同，不同表拆入不同的库，专库专表
        分析：公用的配置表拆到单独的库中，可以服务化
        
    垂直分表：（详情表、展示表）
        以字段活跃性为依据，将表中字段拆到不同的表（主表和扩展表）中。
        问题：查询时读磁盘产生大量随机读io，产生io瓶颈。
            修改热点数据会影响读热点数据。
        分析：每个表字段至少有一列交集，一般是主键，用于关联数据。且查询关联数据应在Service层做文章
            ，因为join增加cpu负担且必须在一个数据库实例上。
            
    水平分库：以字段为依据，将一个库中的表拆到多个数据库中。
        分析：系统绝对并发量上来了，分表不能解决根本问题
            库多了，io和cpu的压力就降下来了
            
    水平分表：以字段为依据，将一个表拆为多个表
        分析：系统的绝对并发量没有上来，只是因为单表的数据量太多，影响sql效率，加重cpu负担
            表数据量少了，单词sql知性效率高，自然减轻cpu压力
            
    1数据库在设计时就要考虑垂直分库，垂直分表
    2优先考虑缓存处理，读写分离，使用索引等方式，不行再做水平分库和水平分表。
    3工具：sharding-sphere、Mycat

四十六、分库分表带来什么问题？
    1.事务一致性问题
        当更新内容同时分布在不同库中，就会有跨库事务问题。一般采用“XA协议”和“两阶段提交处理”。
        分布式事务在提交事务时需要协调多个节点，推后了提交事务的时间点，延长事务		执行时间。导致事务在访问共享资源时发生冲突或死锁的概率提高。所以对于		性能要求很高，但对一致性要求不高的系统，可以在允许的时间达到最终一致		性即可。
    2.跨节点关联查询join问题。
        数据可能分布在不同节点上，考虑性能，尽量避免使用join查询。
            1.建立全局表，即字典表，把系统中所有模块都可能依赖的表，这些数据通常会很少修改，在每个数据库中都保存一份。
            2.字段冗余，空间换时间避免join。适用场景有限，会出现冗余字段数据一致性问题。
            3.数据组装，在服务层多次查询，将数据拼装
            4.ER分片，如果表之间关联关系明显，可以放到同一个分片上。
    3.跨节点分页，排序，函数问题。
        Limit分页，order by排序，Max、Sum函数。可能都需要在不同分片排序返回，再	将所有结果汇总再次排序。
    4.主键重复问题。
        UUID、SnowFlake分布式自增ID算法
        
四十七、beanfactory和applicationcontext的区别？
    applicationcontext是BeanFactory的子接口，功能更完整，一般情况都用它。 
    BeanFactory：
        1、延时加载，节约内存，但是程序启动时不一定容易发现配置问题
        2、以编程方式被创建
        3、支持BeanPostProcessor，BeanFactoryPostProcessor，需要手动注册
    ApplicationContext：
        1、容器启动时全部加载，占用内存，容易启动时发现配置错误，运行快
        2、以编程、生命方式被创建
        3、支持BeanPostProcessor，BeanFactoryPostProcessor，需要手动注册
        
四十八、解释MVCC？
    多版本并发控制：读取时通过一种快照的方式将数据保存，使得读锁和写锁不冲突。只工作在读已提交和可重复读两个隔离级别下。
    在InnoDB引擎表中，它的聚簇索引记录中有两个必要的隐藏列：
    trx_id：
        这个id用来存储的每次对某条聚簇索引记录进行修改的时候的事务id。
    roll_pointer：
        每次对哪条聚簇索引记录有修改的时候，都会把老版本写入undo日志中。这个roll_pointer就是存了一个指针，它指向这条聚簇索引记录的上一个版本的位置，通过它来获得上一个版本的记录信息。(注意插入操作的undo日志没有这个属性，因为它没有老版本)
    
    开始事务创建ReadView，ReadView维护当前活动事务的id，即未提交事务的id，为一个排序数组。
    访问数据时，获取数据中的最大事务id和ReadView对比，在左边意味该事务已提交，可以访问。
    在右边或者在ReadView中，意味还未提交。不可访问，通过roll_pointer获取上一版本号重新对比。
    
    读已提交隔离级别下的事务在每次查询的开始都会生成一个独立的ReadView,而可重复读隔离级别则在第一次读的时候生成一个ReadView，之后的读都复用之前的ReadView。
    
四十九、为什么Java中不支持多重继承？
    1.第一个原因是围绕钻石💎形继承问题产生的歧义。
    2.多重继承确实使设计复杂化并在转换、构造函数链接等过程中产生问题。假设你需要多重继承的情况并不多，简单起见，明智的决定是省略它。
        此外，Java 可以通过使用接口支持单继承来避免这种歧义。由于接口只有方法声明而且没有提供任何实现，因此只有一个特定方法的实现，因此不会有任何歧义。
        
五十、MyBatis 的工作原理？
    1）读取 MyBatis 配置文件：mybatis-config.xml 为 MyBatis 的全局配置文件，配置了 MyBatis 的运行环境等信息，例如数据库连接信息。

    2）加载映射文件。映射文件即 SQL 映射文件，该文件中配置了操作数据库的 SQL 语句，需要在 MyBatis 配置文件 mybatis-config.xml 中加载。mybatis-config.xml 文件可以加载多个映射文件，每个文件对应数据库中的一张表。

    3）构造会话工厂：通过 MyBatis 的环境等配置信息构建会话工厂 SqlSessionFactory。

    4）创建会话对象：由会话工厂创建 SqlSession 对象，该对象中包含了执行 SQL 语句的所有方法。

    5）Executor 执行器：MyBatis 底层定义了一个 Executor 接口来操作数据库，它将根据 SqlSession 传递的参数动态地生成需要执行的 SQL 语句，同时负责查询缓存的维护。

    6）MappedStatement 对象：在 Executor 接口的执行方法中有一个 MappedStatement 类型的参数，该参数是对映射信息的封装，用于存储要映射的 SQL 语句的 id、参数等信息。

    7）输入参数映射：输入参数类型可以是 Map、List 等集合类型，也可以是基本数据类型和 POJO 类型。输入参数映射过程类似于 JDBC 对 preparedStatement 对象设置参数的过程。

    8）输出结果映射：输出结果类型可以是 Map、 List 等集合类型，也可以是基本数据类型和 POJO 类型。输出结果映射过程类似于 JDBC 对结果集的解析过程。

五十一、为什么建议innodb表必须建主键，并且推荐使用整形的自增主键？
    如果设置了主键，那么InnoDB会选择主键作为聚集索引、如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引、
        如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引(ROWID随着行记录的写入而主键递增)。
        我们为了节约数据库资源，为了性能高，节约开销，尽量去要建立主键。

    如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，主键的顺序按照数据记录的插入顺序排列，自动有序。当一页写满，就会自动开辟一个新的页
    如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置，此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，
        这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。
    使用整形的自增主键，维护、查找B+树时，对索引比较及排序会更快，同时也能节约内存空间。

五十二、mysql最左前缀优化原则？
    索引的底层是一颗B+树，那么联合索引的底层也就是一颗B+树，只不过联合索引的B+树节点中存储的是键值。由于构建一棵B+树只能根据一个值来确定索引关系，
    所以MySQL创建联合索引的规则是首先会对联合索引的最左边第一个字段排序，在第一个字段的排序基础上，然后在对第二个字段进行排序。如果不通过匹配左边的字段时，相当于是在无序的表中进行全表查询。

五十三、MYSQL相关tips？
    1、本身innodb可以没有主键。
    2、innodb的页默认16kb。
    3、表放在安装目录下的data文件夹中

五十四、Spring两种代理方式
　　若目标对象实现了接口，spring默认使用JDK的动态代理。
　　优点：因为有接口，所以使系统更加松耦合；
　　缺点：为每一个目标类创建接口；

　　若目标对象没有实现任何接口，spring使用CGLib进行动态代理。
　　优点：因为代理类与目标类是继承关系，所以不需要有接口的存在。
　　缺点：因为没有使用接口，所以系统的耦合性没有使用JDK的动态代理好。

五十五、简述Spring AOP的实现原理？
    以CGLib为例，在行postProcessAfterInitialization阶段，通过ProxyFactoryBean获取动态代理对象。
    其中代理类有一个叫做target的属性，值是父类对象（原对象）。
    当我们调用代理方法时，触发CglibAopProxy.intercept()方法，获得一个拦截器链，按这个拦截器链来执行增强方法，其中业务逻辑主要是调用target.方法

五十六、BeanFactory 和 FactoryBean的区别？
    BeanFactory是个Factory，也就是IOC容器或对象工厂，在Spring中，所有的Bean都是由BeanFactory(也就是IOC容器)来进行管理的，提供了实例化对象和拿对象的功能。
    FactoryBean是个Bean，这个Bean不是简单的Bean，而是一个能生产或者修饰对象生成的工厂Bean,它的实现与设计模式中的工厂模式和修饰器模式类似。

五十七、Spring 是如何管理事务的，事务管理机制？
    Spring的事务机制包括声明式事务和编程式事务。
        编程式事务管理：Spring推荐使用TransactionTemplate，实际开发中使用声明式事务较多。
        声明式事务管理：将我们从复杂的事务处理中解脱出来，获取连接，关闭连接、事务提交、回滚、异常处理等这些操作都不用我们处理了，Spring都会帮我们处理。
            声明式事务管理使用了AOP面向切面编程实现的，本质就是在目标方法执行前后进行拦截。在目标方法执行前加入或创建一个事务，在执行方法执行后，根据实际情况选择提交或是回滚事务。

    如何管理的：
    Spring事务管理主要包括3个接口，Spring的事务主要是由它们(PlatformTransactionManager，TransactionDefinition，TransactionStatus)三个共同完成的。
    1. PlatformTransactionManager：事务管理器--主要用于平台相关事务的管理
        主要有三个方法：
            commit 事务提交；
            rollback 事务回滚；
            getTransaction 获取事务状态。

    2. TransactionDefinition：事务定义信息--用来定义事务相关的属性，给事务管理器PlatformTransactionManager使用
        这个接口有下面四个主要方法：
            getIsolationLevel：获取隔离级别；
            getPropagationBehavior：获取传播行为；
            getTimeout：获取超时时间；
            isReadOnly：是否只读（保存、更新、删除时属性变为false--可读写，查询时为true--只读）
        事务管理器能够根据这个返回值进行优化，这些事务的配置信息，都可以通过配置文件进行配置。

    3. TransactionStatus：事务具体运行状态--事务管理过程中，每个时间点事务的状态信息。

        例如它的几个方法：
            hasSavepoint()：返回这个事务内部是否包含一个保存点，
            isCompleted()：返回该事务是否已完成，也就是说，是否已经提交或回滚
            isNewTransaction()：判断当前事务是否是一个新事务

    声明式事务的优缺点：
    优点：不需要在业务逻辑代码中编写事务相关代码，只需要在配置文件配置或使用注解（@Transaction），这种方式没有侵入性。
    缺点：声明式事务的最细粒度作用于方法上，如果像代码块也有事务需求，只能变通下，将代码块变为方法。

五十八、Spring 中用到了那些设计模式？
    Spring框架中使用到了大量的设计模式，下面列举了比较有代表性的：
        代理模式—在AOP和remoting中被用的比较多。
            Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么Spring AOP会使用JDK Proxy，去创建代理对象，而对于没有实现接口的对象，这时候Spring AOP会使用Cglib 生成一个被代理对象的子类来作为代理
        单例模式—在spring配置文件中定义的bean默认为单例模式。
            Spring默认将所有的Bean设置成 单例模式，即对所有的相同id的Bean的请求，都将返回同一个共享的Bean实例。这样就可以大大降低Java创建对象和销毁时的系统开销。
        模板方法—用来解决代码重复的问题。比如. RestTemplate, jdbcTemplate, redisTemplate。
            模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤的实现方式。Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。
        工厂模式—BeanFactory用来创建对象的实例。
            Spring使用工厂模式可以通过 BeanFactory 或 ApplicationContext 创建 bean 对象。
        适配器--spring mvc
            每一个Controller都有一个适配器与之对应，而各个适配器Adapter又都是适配器接口HandlerAdapter的实现类，我们就可以统一通过适配器的hanle()方法来调用Controller中的用于处理请求的方法。
        装饰器--spring data hashmapper

        观察者-- spring 时间驱动模型
            定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 spring中Observer模式常用的地方是listener的实现。如ApplicationListener。
        回调--Spring ResourceLoaderAware回调接口

五十九、springboot自动配置的原理

    在spring程序main方法中 添加@SpringBootApplication或者@EnableAutoConfiguration
    会自动去maven中读取每个starter中的META-INF/spring.factories文件 该文件里配置了所有需要被创建spring容器中的bean

六十、什么情况下设置了索引但无法使用
    （1）以“%”开头的 LIKE 语句，模糊匹配
    （2）OR 语句前后没有同时使用索引
    （3）存在索引列的数据类型隐形转换，则用不上索引，比如列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引
    （4）where 子句里对索引列上有数学运算，用不上索引
    （5）最左前缀原则
    （6）如果mysql估计使用全表扫描要比使用索引快,则不使用索引，比如数据量极少的表

六十一、什么情况下不推荐使用索引？
    1) 数据唯一性差（一个字段的取值只有几种时）的字段不要使用索引
        比如性别，只有两种可能数据。意味着索引的二叉树级别少，多是平级。这样的二叉树查找无异于全表扫描。

    2) 频繁更新的字段不要使用索引
        比如logincount登录次数，频繁变化导致索引也频繁变化，增大数据库工作量，降低效率。

    3) 字段不在where语句出现时不要添加索引,如果where后含IS NULL /IS NOT NULL/ like ‘%输入符%’等条件，不建议使用索引
        只有在where语句出现，mysql才会去使用索引

    4） where 子句里对索引列使用不等于（<>），使用索引效果一般

六十二、ReentrantReadWriteLock读写状态的设计？
    读写锁对于同步状态的实现是在一个整形变量上通过“按位切割使用”：将变量切割成两部分，高16位表示读，低16位表示写。
    写锁的获取与释放：
        调用的独占式同步状态的获取与释放，因此真实的实现就是Sync的 tryAcquire和 tryRelease。
    读锁的获取与释放：
        类似于写锁，读锁的lock和unlock的实际实现对应Sync的 tryAcquireShared 和 tryReleaseShared方法。

    如果已经有线程获取了写锁，则其他任何线程如果尝试获取读写锁都会失败。
    如果已经有线程获取了读锁，其他线程尝试获取读锁时，需要判断阻塞队列的第一个阻塞线程尝试获取的锁的类型，如果是读锁，
        则可以非公平的竞争读锁。如果是写锁，则加入阻塞队列，在两次尝试获取读锁失败后被挂起。
    区别在读锁只有尝试写锁的时候才放到等待队列，而写锁是只要非当前线程尝试加锁（无论写锁还是读锁）都会放到等待队列。

六十三、Netty模型
    Netty拥有两个NIO线程池，分别是bossGroup和workerGroup，前者处理新建连接请求，然后将新建立的连接轮询交给workerGroup中的其中一个NioEventLoop来处理，后续该连接上的读写操作都是由同一个NioEventLoop来处理。
    BossGroup 和 WorkerGroup 类型都是 NioEventLoopGroup，这个组中可以含有多个NioEventLoop
    每个Boss NioEventLoop 循环执行的步骤有3步
        1、轮询accept 事件 ，2、处理accept 事件 ，与client建立连接 , 生成NioScocketChannel , 并将其注册到某个worker NIOEventLoop 上的 selector，
        3、处理任务队列的任务 ， 即 runAllTasks；
    每个 Worker NIOEventLoop 循环执行的步骤 ：
        1、轮询read, write 事件 处理i/o事件， 即read , write 事件，2、在对应NioScocketChannel 处理，
        3、处理任务队列的任务 ， 即 runAllTasks ；
    每个Worker NIOEventLoop  处理业务时，会使用pipeline(管道)执行的, pipeline 中包含了 channel , 即通过pipeline 可以获取到对应通道, 管道中维护了很多的 处理器。

六十四、tcp粘包、解决办法？
    一次接收到了客户端发送过来的一个完整的数据包
    一次接收到了客户端发送过来的 N 个数据包，由于每个包的长度不定，无法将各个数据包拆开
    一次接收到了一个或者 N 个数据包 + 下一个数据包的一部分，还是很悲剧，无法将数据包拆开
    一次收到了半个数据包，下一次接收数据的时候收到了剩下的一部分 + 下个数据包的一部分，更悲剧，头大了

    1使用标准的应用层协议（比如：http、https）来封装要传输的不定长的数据包
    2在每条数据的尾部添加特殊字符，如果遇到特殊字符，代表当条数据接收完毕了
        有缺陷：效率低，需要一个字节一个字节接收，接收一个字节判断一次，判断是不是那个特殊字符串
    3在发送数据块之前，在数据块最前边添加一个固定大小的数据头，这时候数据由两部分组成：数据头 + 数据块
        数据头：存储当前数据包的总字节数，接收端先接收数据头，然后在根据数据头接收对应大小的字节
        数据块：当前数据包的内容

六十五、JAVA8新特性
    1.Lambda 表达式
        Lambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中）。
        使用Lambda 表达式可以使代码变的更加简洁紧凑。
    2.Java 8 方法引用
        方法引用通过方法的名字来指向一个方法。
        方法引用可以使语言的构造更紧凑简洁，减少冗余代码。
        方法引用使用一对冒号 :: 。
    3.Java 8 新增了接口的默认方法。
    4.Stream
        Java 8 API添加了一个新的抽象称为流Stream，可以让你以一种声明的方式处理数据。
        将要处理的元素集合看作一种流，流在管道中传输，并且可以在管道的节点上进行处理，比如filter，sorted，映射map，聚合collect等
    5.Optional 类
        Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。
        Optional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。
        Optional 类的引入很好的解决空指针异常。

六十六、Java 浅拷贝和深拷贝的理解和实现方式
    浅拷贝的实现方式主要有三种：
        一、通过拷贝构造方法实现浅拷贝：
            Person p1=new Person(a,"被拷贝");
            Person p2=new Person(p1);
            相当于复制出一个新引用
        二、通过重写clone()方法进行浅拷贝
            通过super.clone()调用Object类中的原clone方法（被protected修饰，无法直接用），直接返回克隆出的obj（引用）
    深拷贝的实现方法主要有两种：
        一、通过重写clone方法来实现深拷贝
            每一层的每个对象都进行浅拷贝=深拷贝
        二、通过对象序列化实现深拷贝
            将对象序列化为字节序列后，默认会将该对象的整个对象图进行序列化，再通过反序列即可完美地实现深拷贝。

六十七、RabbitMQ常用的五种模型?
    第一种：简单模式 Simple
        一个队列丶一个消费者。
    第二种：工作模式 Work
        一个队列丶多个消费者。
    第三种：广播模式 (fanout)
        多个消费者，每一个消费这都有自己的队列，每个队列都绑定到交换机
        交换机把消息发送给绑定过的所有队列；队列的消费者都能拿到消息。fanout类型转发消息是最快的
    第四种：路由模式 Routing(direct)
        消息的路由键（rounting key）如果和binding key一致，交换机根据路由key发送给对应队列。是完全匹配，一对一的模式。
    第五种：主题Topic模式
        Topics模式和direct路由模式类似，交换器通过模式匹配分配消息的消息的路由键（rounting key），分发到对应的队列上。
        符号(通配符)：#表示匹配0个或者多个词、*表示匹配一个词

六十八、如何保证消息队列MQ数据不丢失？
    对于生产者：
        生产者（Producer） 通过网络发送消息给 Broker，当 Broker 收到之后，将会返回确认响应信息给 Producer。所以生产者只要接收到返回的确认响应，就代表消息在生产阶段未丢失。
    对于MQ：
        Q:rabbitMQ成功接收到了消息并保存在内存中, 但是在仓储服务没有拿走此消息之前, rabbitMQ宕机了. 怎么办?
        A:此问题需要考虑消息持久化(durable机制), 通过设置队列的durable参数为true, 则当rabbitMQ重启之后, 会恢复之前的队列。
        它的工作原理是rabbitMQ会把队列的相关信息持久化到磁盘.
    对于消费者：
        Q:接收到一条订单消息之后, 并对此条消息没有处理完之前,突然宕机了?
        A: rabbitMQ默认操作是当消费者成功接收到消息之后,rabbitMQ则会自动的在队列中将此条消息删除. 这种操作称为自动ACK(自动回复).
             核心痛点就在于autoAck这个参数. 需要将此参数设置为false. 当此参数设置为false. 那么当消费者接收到这个消息之后,消息队列也不会马上删除这条消息.
             对于我们开发人员要做的就是只有执行成功之后才会向消息对返回一条确认消息,当消息队列接收到这条消息之后才删除消息
        Q:基于ack机制,结合高并发场景会出现什么问题?
        A: 每一个channel都会存在若干的unack消息(未确认消息).
            比方说, rabbitMQ正在发送的消息 、 消费者实例接收到消息之后但没有处理完 、 执行了ack但是因为ack是异步的也不会马上变为ack信息 、 开始批量ack延迟时间会更长.
                此时如果rabbitMQ无限制的过多过快的向消费者实例发送消息,就会导致庞大的unack消息积压在消费者实例的内存中,如果继续保持发与积压的状态,最终会导致消费者实例的oom!!.
            此时需要考虑消费者实例的处理能力以及如何解决unack消息积压的问题.可以考虑 提高消费者的消费能力。
                同时rabbitMQ基于 prefetch count(预抓取总数)控制每一个channel的unack消息的数量。 当一个channel中的unack消息超过阈值之后, rabbitMQ则会停止向这个消费者实例投递消息,
                等待unack消息总数小于阈值 或者 将消息转发给其他的消费者实例.这个阈值过大可能导致系统雪崩, 过小导致系统吞吐量过低,响应速度低.
        Q：当前队列节点挂了，存储节点硬盘又坏了，消息丢了，怎么办？
            消息补偿机制。消息补偿机制需要建立在业务数据库和MQ数据库的基础之上 , 当我们发送消息时 , 需要同时将消息数据保存在数据库中, 两者的状态必须记录。
                然后通过业务数据库和MQ数据库的对比检查消费是否成功，不成功，进行消息补偿措施，重新发送消息处理

六十九、消息积压你是怎么处理的？
    设计系统时，要保证消费端的消费性能要高于生产者的发送性能，这样系统才能健康持续运行。
    消息积压产生的原因有2种：第一是消息生产速度过快，另一种是消息消费速度变慢。可以通过查看消息队列内置的监控数据，确定是生产端还是消费端的原因。

    如果是消费端的原因，就进行消费端性能优化：
        首先可以优化消费业务逻辑，尽量减少冗余。还可以增加消费端的并发数，也就是扩容Consumer实例，也必须同步扩容主题中的队列数量，确保Consumer的实例数量和队列数量相等。
        如果是有大促或者抢购导致消息突增，短时间内不可能通过优化代码来解决，唯一的方法是通过增加消费者实例数来提升总体的消费能力。
            如果短时间内没有足够的服务器资源进行扩容，那么可以将系统降级，关闭一些不重要的业务，减少生产者生产的消息数量，让系统尽可能正常运转，服务一些重要的业务。
        如果通过监控发现生产消息的速度和消费消息的速度都没有什么异常，那就需要检查一下消费端，是不是消费失败导致了一条消息反复消息。
        如果监控到消费变慢了，需要检查一下消费实例，分析一下是什么原因导致消费变慢。可以检查一下日志看是否有大量的消费错误，还可以通过打印堆栈信息，看一下消费线程是不是卡在什么地方了，比如发生死锁或者等待资源。

七十、RabbitMQ、RocketMQ、Kafka，都有可能会出现消息重复消费的问题，如何解决？
    消费端处理消息的业务逻辑保持幂等性。幂等性，通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。

    比如，你拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
    再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。
    如果上面两种情况还不行，上大招。准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将<id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。